{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_name = \"l3harris\" # \"l3harris\" or \"novateur\"\n",
    "out_dir = f\"/data/home/umang/Trajectory_project/anomaly_traj_data/stitch_mount/datassd1_8tb/umang/p2t4_exp_outs/sp_dfs/{sim_name}__train/\"\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/home/umang/Trajectory_project/GPS-MTM'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /data/home/umang/Trajectory_project/anomaly_traj_data/stitch_mount/datassd3_8tb/p1t3_iarpa_data/phase1_trial3/l3harris/trial/poi.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m lat_lons_count_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     10\u001b[0m lat_lons_types_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_poi\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     12\u001b[0m     df_poi_lat \u001b[38;5;241m=\u001b[39m df_poi\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     df_poi_lon \u001b[38;5;241m=\u001b[39m df_poi\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "poi_csv_data = f\"/data/home/umang/Trajectory_project/anomaly_traj_data/stitch_mount/datassd3_8tb/p1t3_iarpa_data/phase1_trial3/{sim_name}/trial/poi.csv\"\n",
    "\n",
    "try:\n",
    "    df_poi = pd.read_csv(poi_csv_data)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {poi_csv_data}\")\n",
    "    df_poi = None\n",
    "\n",
    "lat_lons_count_dict = {}\n",
    "lat_lons_types_dict = {}\n",
    "for i in range(len(df_poi)):\n",
    "    df_poi_lat = df_poi.iloc[i][\"lat\"]\n",
    "    df_poi_lon = df_poi.iloc[i][\"lon\"]\n",
    "    df_poi_category = df_poi.iloc[i][\"poi_category\"]\n",
    "\n",
    "    if (df_poi_lat, df_poi_lon) not in lat_lons_count_dict:\n",
    "        lat_lons_count_dict[(df_poi_lat, df_poi_lon)] = 1\n",
    "        lat_lons_types_dict[(df_poi_lat, df_poi_lon)] = set([df_poi_category])\n",
    "    else:\n",
    "        lat_lons_count_dict[(df_poi_lat, df_poi_lon)] += 1\n",
    "        lat_lons_types_dict[(df_poi_lat, df_poi_lon)].add(df_poi_category)\n",
    "        \n",
    "poi_types_list = [(item, len(item.split(\"__\"))) for item in set([\"__\".join(sorted(list(item))) for item in lat_lons_types_dict.values()])]\n",
    "\n",
    "poi_types_odered = sorted([(str(item[1]).zfill(3)+ \"__\" +item[0]) for item in poi_types_list])\n",
    "poi_types_odered_tuples = [(i, poi_types_odered[i]) for i in range(len(poi_types_odered))]\n",
    "\n",
    "binary_rep_of_pois = dict()\n",
    "for id, poi_type in poi_types_odered_tuples:\n",
    "    poi_type_list = poi_type.split(\"__\")[1:]\n",
    "    binary_rep_of_pois[poi_type] = [0] * (len(poi_types_odered)+2)\n",
    "    binary_rep_of_pois[poi_type][id] = 1\n",
    "\n",
    "poi_embeddings_dict = dict()\n",
    "\n",
    "for lat_lon in lat_lons_types_dict:\n",
    "    poi_string = \"__\".join(sorted(list(lat_lons_types_dict[lat_lon])))\n",
    "    poi_types_count = len(poi_string.split(\"__\"))\n",
    "    \n",
    "    poi_string_full = str(poi_types_count).zfill(3) + \"__\" + poi_string\n",
    "    poi_embedding = binary_rep_of_pois[poi_string_full]\n",
    "    poi_embeddings_dict[lat_lon] = poi_embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nighttime_stops(df):\n",
    "    # Convert timestamps to datetime\n",
    "    df[\"stay_start_timestamp\"] = pd.to_datetime(df[\"stay_start_timestamp\"])\n",
    "    df[\"stay_end_timestamp\"] = pd.to_datetime(df[\"stay_end_timestamp\"])\n",
    "    \n",
    "    # Define the nighttime period (8 PM to 6 AM)\n",
    "    night_start = 20  # 8 PM\n",
    "    night_end = 6  # 6 AM\n",
    "\n",
    "    def calculate_intersection(row):\n",
    "        total_intersection = 0\n",
    "        current = row[\"stay_start_timestamp\"]\n",
    "        end = row[\"stay_end_timestamp\"]\n",
    "        \n",
    "        while current < end:\n",
    "            if (current.hour >= night_start) or (current.hour < night_end):\n",
    "                next_hour = current.replace(minute=0, second=0) + pd.Timedelta(hours=1)\n",
    "                next_time = min(next_hour, end)\n",
    "                total_intersection += (next_time - current).total_seconds()\n",
    "            current += pd.Timedelta(hours=1)\n",
    "        \n",
    "        return total_intersection\n",
    "\n",
    "    df[\"intersection_time\"] = df.apply(calculate_intersection, axis=1)\n",
    "\n",
    "    # Aggregate by latitude and longitude\n",
    "    result = df.groupby([\"min_poi_lat\", \"min_poi_lon\"], as_index=False)[\"intersection_time\"].sum()\n",
    "    \n",
    "    # sort by intersection time\n",
    "    result = result.sort_values(by=\"intersection_time\", ascending=False)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file_name = os.listdir(out_dir)[0]\n",
    "def get_states_and_actions(df_file_name):\n",
    "    try:\n",
    "        df_path = os.path.join(out_dir, df_file_name)\n",
    "        df = pd.read_csv(df_path)\n",
    "        \n",
    "        import copy\n",
    "        df_copy = copy.deepcopy(df)\n",
    "        \n",
    "        night_stops = get_nighttime_stops(df_copy)\n",
    "        most_visted_stop_lat = night_stops.iloc[0][\"min_poi_lat\"]\n",
    "        most_visted_stop_lon = night_stops.iloc[0][\"min_poi_lon\"]\n",
    "        home_lat_lon = (most_visted_stop_lat, most_visted_stop_lon)\n",
    "\n",
    "        poi_embeddings_list = []\n",
    "        for row_index in range(len(df)):\n",
    "            df_poi_lat = df.iloc[row_index][\"min_poi_lat\"]\n",
    "            df_poi_lon = df.iloc[row_index][\"min_poi_lon\"]\n",
    "            poi_lat_lon = (df_poi_lat, df_poi_lon)\n",
    "            if poi_lat_lon != home_lat_lon:\n",
    "                df_poi_embedding = poi_embeddings_dict[(df_poi_lat, df_poi_lon)]\n",
    "                # df.at[row_index, \"poi_embedding\"] = str(df_poi_embedding)\n",
    "                poi_embeddings_list.append(df_poi_embedding)\n",
    "            else:\n",
    "                # print(\"Found home location\")\n",
    "                df_poi_embedding = [0]*len(poi_types_odered) + [1, 0]\n",
    "                poi_embeddings_list.append(df_poi_embedding)\n",
    "                \n",
    "            \n",
    "        # append rows with zeros to the poi_embeddings_list to make it with 221 rows\n",
    "        poi_embeddings_list = poi_embeddings_list + [[0]*len(poi_types_odered) + [0, 1]]*(221-len(poi_embeddings_list))\n",
    "\n",
    "        final_data = dict()\n",
    "        final_data[\"obs\"] = np.array(poi_embeddings_list)\n",
    "        \n",
    "        import datetime\n",
    "        # type(df[\"stay_start_timestamp\"].iloc[0])\n",
    "        sp_time_duration_list = []\n",
    "        min_day_of_year, max_day_of_year = 274, 305\n",
    "        for row_index in range(len(df)):\n",
    "            stay_start_timestamp = df.iloc[row_index][\"stay_start_timestamp\"]\n",
    "            \n",
    "            stay_start_timestamp = datetime.datetime.strptime(stay_start_timestamp, \"%Y-%m-%d %H:%M:%S+00:00\")\n",
    "            \n",
    "            # day of the year\n",
    "            day_of_year = stay_start_timestamp.timetuple().tm_yday\n",
    "            day_of_year_normalized = (day_of_year - min_day_of_year) / (1.0*(max_day_of_year - min_day_of_year))\n",
    "            # hour of the day\n",
    "            hour_of_day = stay_start_timestamp.hour / 24.0\n",
    "            # minute of the hour\n",
    "            minute_of_hour = stay_start_timestamp.minute / 60.0\n",
    "            \n",
    "            # print(day_of_year, hour_of_day, minute_of_hour)\n",
    "            stay_duration_in_secs = df.iloc[row_index][\"stay_duration_in_secs\"]\n",
    "            # convert stay_duration_in_secs from seconds to (num_days, num_hours, num_minutes, num_seconds)\n",
    "            num_days = stay_duration_in_secs // (24*60*60)\n",
    "            num_hours = (stay_duration_in_secs % (24*60*60)) // (60*60)\n",
    "            num_minutes = (stay_duration_in_secs % (60*60)) // 60\n",
    "            num_seconds = stay_duration_in_secs % 60\n",
    "            \n",
    "            normalized_num_days = num_days / (max_day_of_year - min_day_of_year)\n",
    "            normalized_num_hours = num_hours / 24.0\n",
    "            normalized_num_minutes = num_minutes / 60.0\n",
    "            normalized_num_seconds = num_seconds / 60.0\n",
    "            \n",
    "            sp_time_duration_list.append([day_of_year_normalized, \n",
    "                                        hour_of_day, \n",
    "                                        minute_of_hour, \n",
    "                                        normalized_num_days, \n",
    "                                        normalized_num_hours, \n",
    "                                        normalized_num_minutes])\n",
    "            \n",
    "        # add more rows with zeros to make it 221 rows\n",
    "        sp_time_duration_list = sp_time_duration_list + [[0]*6]*(221-len(sp_time_duration_list))\n",
    "            \n",
    "        final_data[\"act\"] = sp_time_duration_list\n",
    "        \n",
    "        attention_mask = np.array([1]*len(df) + [0]*(221-len(df)))\n",
    "        final_data[\"att_mask\"] = attention_mask\n",
    "        \n",
    "        npzs_dir = f\"/datassd1_8tb/users/chandrakanth/p2t4_exp_outs/sp_npzs_47class/{sim_name}__train/\"\n",
    "        if not os.path.exists(npzs_dir):\n",
    "            os.makedirs(npzs_dir)\n",
    "        # npz_file_name = df_file_name.replace(\".csv\", \".npz\")\n",
    "        agent_id = df_file_name.split(\"_\")[1]\n",
    "        npz_file_name = f\"agent_{agent_id}.npz\"\n",
    "        npz_file_path = os.path.join(npzs_dir, npz_file_name)\n",
    "        np.savez(npz_file_path, **final_data)\n",
    "        \n",
    "        return final_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing {df_file_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_1k_list = os.listdir(out_dir)[:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1010 [00:00<00:11, 80.95it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "  5%|▌         | 55/1010 [00:00<00:11, 85.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_100738_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 82/1010 [00:00<00:11, 82.75it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      "  9%|▉         | 92/1010 [00:01<00:10, 85.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_439056_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 137/1010 [00:01<00:10, 81.81it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 15%|█▌        | 156/1010 [00:01<00:10, 85.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_114028_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 210/1010 [00:02<00:09, 83.29it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 22%|██▏       | 220/1010 [00:02<00:09, 85.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_74557_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 285/1010 [00:03<00:08, 85.37it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 30%|███       | 304/1010 [00:03<00:08, 84.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_348080_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 349/1010 [00:04<00:07, 84.22it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 36%|███▌      | 359/1010 [00:04<00:07, 87.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_165348_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 523/1010 [00:06<00:05, 85.56it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 54%|█████▎    | 541/1010 [00:06<00:05, 86.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_207869_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 694/1010 [00:08<00:03, 82.23it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 70%|███████   | 712/1010 [00:08<00:03, 83.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_95210_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 856/1010 [00:10<00:01, 82.83it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 86%|████████▌ | 865/1010 [00:10<00:01, 84.82it/s]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2719348/9832419.py\", line 5, in get_states_and_actions\n",
      "    df = pd.read_csv(df_path)\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chandrakanth/ck_code/p1t2_gen_fas_3/.conda/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"parsers.pyx\", line 581, in pandas._libs.parsers.TextReader.__cinit__\n",
      "pandas.errors.EmptyDataError: No columns to parse from file\n",
      " 87%|████████▋ | 875/1010 [00:10<00:01, 88.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in processing agent_437510_sp_df.csv: No columns to parse from file\n",
      "Error in processing agent_395974_sp_df.csv: No columns to parse from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1010/1010 [00:12<00:00, 83.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "res_list = []\n",
    "for agent_id_temp in tqdm(agents_1k_list):\n",
    "    res = get_states_and_actions(agent_id_temp)\n",
    "    res_list.append((res, agent_id_temp))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datassd1_8tb/users/chandrakanth/p2t4_exp_outs/sp_npzs_47class/l3harris__train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m npzs_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datassd1_8tb/users/chandrakanth/p2t4_exp_outs/sp_npzs_47class/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__train/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m npz_file_name \u001b[38;5;241m=\u001b[39m (\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpzs_dir\u001b[49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m npz_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(npzs_dir, npz_file_name)\n\u001b[1;32m      4\u001b[0m npz_file_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(npz_file_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datassd1_8tb/users/chandrakanth/p2t4_exp_outs/sp_npzs_47class/l3harris__train/'"
     ]
    }
   ],
   "source": [
    "npzs_dir = f\"/datassd1_8tb/users/chandrakanth/p2t4_exp_outs/sp_npzs_47class/{sim_name}__train/\"\n",
    "npz_file_name = (os.listdir(npzs_dir))[0]\n",
    "npz_file_path = os.path.join(npzs_dir, npz_file_name)\n",
    "npz_file_data = np.load(npz_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_file_data[\"obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
