{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/data/home/umang/Trajectory_project/GPS-MTM/outputs/test_geolife/2025-08-27_10-47-20/test_outputs/random_masking_0.5_testing/RANDOM\"\n",
    "pred_pickle_path=\"{}/predictions_batch_6.pkl\".format(folder)\n",
    "batch_pickle_path = \"{}/ground_truth_batch_6.pkl\".format(folder)\n",
    "attention_pickle_path = \"{}/attention_masks_batch_6.pkl\".format(folder)\n",
    "masks_pickle_path = \"{}/masks_batch_6.pkl\".format(folder)\n",
    "with open(pred_pickle_path, 'rb') as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "with open(batch_pickle_path, 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "with open(attention_pickle_path, 'rb') as f:\n",
    "    attention_masks = pickle.load(f)\n",
    "\n",
    "with open(masks_pickle_path, 'rb') as f:\n",
    "    masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2549])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks['states'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2549, 198])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"states\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2549, 11])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"actions\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most frequently top-5 most repeated in ground_truth_list_States\n",
    "# #don't use torch top-k..\n",
    "ground_truth_list_states = []\n",
    "for i in range(len(attention_masks)):\n",
    "     # first zero mask is first time when attention_masks[i] becomes zero\n",
    "    zero_indices = (attention_masks[i].flatten() == 0).nonzero(as_tuple=True)[0]\n",
    "    first_zero_mask = zero_indices[0].item() if len(zero_indices) > 0 else attention_masks[i].numel()\n",
    "    \n",
    "    ground_truth_states= batch[\"states\"][i, :first_zero_mask, :]\n",
    "    ground_truth_states = torch.argmax(ground_truth_states, dim=-1)\n",
    "    ground_truth_list_states.append(ground_truth_states)\n",
    "\n",
    "k=4\n",
    "ground_truth_list_states = torch.cat(ground_truth_list_states).flatten()\n",
    "unique, counts = torch.unique(ground_truth_list_states, return_counts=True)\n",
    "top_k_ground_truth = unique[torch.topk(counts, k=k).indices]\n",
    "top_k_ground_truth\n",
    "\n",
    "top_1_ground_truth = unique[torch.topk(counts, k=1).indices]\n",
    "top_4_ground_truth = unique[torch.topk(counts, k=4).indices]    \n",
    "# top_5_ground_truth = unique[torch.topk(counts, k=5).indices]\n",
    "# top_10_ground_truth = unique[torch.topk(counts, k=10).indices]\n",
    "# top_20_ground_truth = unique[torch.topk(counts, k=20).indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  3.0000,  ...,  0.2430,  0.1561, -0.1035],\n",
       "        [ 1.0000,  1.0000,  4.0000,  ...,  0.2349,  0.1568, -0.1035],\n",
       "        [ 1.0000,  1.0000,  4.0000,  ...,  0.2351,  0.1564, -0.1035],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['actions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'states': tensor([1, 0, 1,  ..., 1, 1, 1]),\n",
       " 'actions': tensor([1, 0, 1,  ..., 1, 1, 1])}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "predictions_list_states=[]\n",
    "predictions_list_actions=[]\n",
    "ground_truth_list_states=[]\n",
    "ground_truth_list_actions=[]\n",
    "correct_list=[]\n",
    "\n",
    "\n",
    "# Get mask for this sequence\n",
    "mask_states = masks[\"states\"] == 1\n",
    "mask_actions = masks[\"actions\"] == 1\n",
    "\n",
    "net_masks_states= attention_masks* masks[\"states\"]\n",
    "net_masks_actions= attention_masks* masks[\"actions\"]\n",
    "\n",
    "# Apply masks to get only positions where mask is 1\n",
    "predictions_states = predictions[\"states\"][net_masks_states.bool(), :]\n",
    "predictions_actions = predictions[\"actions\"][net_masks_actions.bool(), :]\n",
    "ground_truth_states = batch[\"states\"][net_masks_states.bool(), :]\n",
    "ground_truth_actions = batch[\"actions\"][net_masks_actions.bool(), :]\n",
    "\n",
    "# take argmax of predictions states on last dimension\n",
    "\n",
    "predictions_list_states.append(torch.argmax(predictions_states, dim=-1))\n",
    "predictions_list_actions.append(torch.argmax(predictions_actions, dim=-1))\n",
    "ground_truth_list_states.append(torch.argmax(ground_truth_states, dim=-1))\n",
    "ground_truth_list_actions.append(torch.argmax(ground_truth_actions, dim=-1))\n",
    "\n",
    "print(ground_truth_states)\n",
    "correct = (predictions_states == ground_truth_states).float()\n",
    "correct_list.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "         1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "         1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 1., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_masks_states[..., 0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.3103, -18.5630, -19.0916, -12.4936,   6.2452, -16.9787, -12.8909,\n",
       "         -21.2029, -25.6687, -11.9445, -10.7326, -13.7131, -17.0386, -10.1652,\n",
       "         -15.9799, -15.0842, -23.2234, -12.5690, -14.4104, -11.4185, -15.0160,\n",
       "         -19.0948, -20.3912, -10.6393, -28.7788, -18.0792, -17.0579, -13.0886,\n",
       "         -20.1356, -15.0936, -20.1976, -14.9964, -16.7160, -26.7419, -18.8920,\n",
       "         -13.8157, -18.1270, -30.9393, -28.1965, -14.2142, -22.7878, -17.4191,\n",
       "         -26.2110, -10.9417, -18.2254, -17.1808, -24.7699, -25.0637, -14.4463,\n",
       "         -19.3941, -16.5795, -14.5899, -18.1267, -11.1659, -29.6646, -15.0895,\n",
       "         -19.2787, -26.0587, -18.1465, -20.1063, -21.2770, -21.4669, -26.1188,\n",
       "         -10.9925, -18.1611, -18.5843, -25.9701, -18.3013, -23.3829, -21.8736,\n",
       "         -20.0076, -22.3631, -24.1364, -20.0005, -22.6927, -26.9765, -13.3929,\n",
       "         -22.3499, -19.9872, -18.7133, -25.5618, -22.1150, -21.6509, -17.1083,\n",
       "         -18.7899, -20.9000, -18.9588, -21.7372, -30.5089, -26.1192, -33.5295,\n",
       "         -20.2912, -21.1085, -35.9564, -22.8195, -24.5258, -25.3811, -26.0993,\n",
       "         -19.8777, -28.6453, -21.8129, -22.2608, -24.8029, -36.2268, -26.3820,\n",
       "         -22.0375, -20.1985, -19.3219, -29.5223, -19.4985, -30.1965, -28.9618,\n",
       "         -19.1503, -23.9135, -35.1587, -26.1029, -30.4669, -23.3914, -21.9914,\n",
       "         -22.6901, -23.0522, -29.5165, -34.2689, -31.6181, -31.5082, -27.2768,\n",
       "         -24.8313, -28.6041, -25.4661, -26.3680, -24.6239, -28.8706, -32.1325,\n",
       "         -29.9011, -26.1840, -24.9548, -23.0975, -31.4478, -26.4130, -33.3174,\n",
       "         -22.6044, -20.1363, -25.9132, -34.4485, -24.6130, -20.6185, -29.0450,\n",
       "         -27.0483, -29.2563, -42.2752, -28.6916, -30.0959, -26.1334, -23.5890,\n",
       "         -30.5413, -25.1008, -22.3374, -23.8576, -28.2177, -24.1717, -21.6991,\n",
       "         -27.3435, -30.6864, -29.9701, -32.2667, -24.4265, -28.0296, -27.0839,\n",
       "         -26.4060, -35.1112, -26.5662, -26.0641, -24.6012, -26.6928, -28.5981,\n",
       "         -33.9143, -24.8051, -23.0265, -19.8393, -20.9228, -25.7600, -25.6811,\n",
       "         -29.1039, -24.4026, -31.9349, -33.5492, -32.4715, -28.5120, -31.9781,\n",
       "         -38.2077, -29.6893, -27.3690, -31.6026, -39.2953, -36.4048, -30.1406,\n",
       "         -34.4754, -27.3437],\n",
       "        [-13.2303,  -9.5836, -13.3185,  -9.2063,  -7.9615, -15.1362, -10.9273,\n",
       "          -8.1456, -20.0452,  13.9898, -10.6738,  -5.7441,  -6.6746, -10.9483,\n",
       "          -8.0145,  -9.7339, -17.4600,  -9.9629, -10.1995,  -8.1730,  -8.8149,\n",
       "         -10.1886, -14.0916, -18.0132, -19.7723, -13.7837, -13.4381,  -9.3308,\n",
       "         -10.0080,  -9.5309,  -9.3163, -11.7032, -12.6954, -15.5423,  -9.5274,\n",
       "         -11.5903,  -9.7533, -13.9093, -13.1204, -11.1814, -13.8640, -16.1766,\n",
       "          -7.1863,  -6.0154, -11.3442, -13.1369,  -6.9372, -18.2516,  -9.3521,\n",
       "         -12.5361, -12.3714, -13.5595, -10.7224, -14.8438, -18.6904, -17.1088,\n",
       "         -13.2597,  -8.8176, -13.2004,  -7.8545,  -7.8519, -19.2134, -18.0661,\n",
       "          -5.4709, -11.6318, -12.3707,  -9.1564, -12.1133,  -9.8825, -17.1500,\n",
       "         -10.8831, -12.2435, -13.4116,  -7.8400,  -7.6964, -18.0398, -11.6323,\n",
       "         -10.8198, -10.4740,  -6.5208, -15.8483, -18.8705, -12.8698, -22.2476,\n",
       "         -15.9925, -18.0579, -16.9981, -21.6473, -16.9642, -12.6875, -12.7780,\n",
       "         -13.1343, -13.9499, -12.4137, -14.8311, -17.9326, -16.6984, -14.6102,\n",
       "         -14.4140, -21.4318, -17.8314, -18.7134, -17.4188,  -8.9820, -17.9869,\n",
       "         -11.9757, -11.2095, -13.3099, -13.0909, -16.7642, -23.3173, -17.9001,\n",
       "         -16.6989, -17.5332, -14.8288, -14.4108, -14.9455,  -9.2839, -12.0472,\n",
       "         -12.7409, -15.8611, -12.5366, -19.9358, -13.3663, -19.0968, -17.9834,\n",
       "         -15.7203, -17.2167, -16.7868, -15.9016, -21.0024, -10.8872, -14.7314,\n",
       "         -16.3521, -14.9921, -22.9934, -18.3144, -27.0178, -16.9606, -20.4564,\n",
       "          -9.5810, -16.3633, -15.0489, -25.0153, -18.1973, -12.8472, -15.4099,\n",
       "         -14.5047, -27.2374, -24.6530, -15.3771, -14.7366, -17.2458, -13.6922,\n",
       "         -24.1703, -18.5586, -15.8949, -13.3667, -21.2739, -20.8606, -20.8185,\n",
       "         -17.7430, -20.6212, -17.7686, -16.0878, -25.9277, -19.3807, -19.8356,\n",
       "         -20.9276, -19.7368, -27.5948, -18.6978, -21.0468, -17.3405, -18.7335,\n",
       "         -22.3738, -23.9008, -22.9414, -16.9348, -20.1720, -13.4959, -16.5768,\n",
       "         -12.3167, -24.2803, -19.1411, -18.5906, -20.7533, -29.8721, -17.1560,\n",
       "         -19.4451, -15.0361, -14.4606, -15.0679, -15.1751, -15.0440, -25.2290,\n",
       "         -22.5247, -20.8883],\n",
       "        [ -8.9034, -17.7936, -20.2604,  -9.1437,   9.6446, -15.6519, -11.8969,\n",
       "         -20.3916, -23.0278, -11.4312, -10.5237, -13.6455, -14.7710,  -9.6194,\n",
       "         -12.2654, -13.8452, -22.7738, -12.9167, -13.4909, -12.7969, -12.1899,\n",
       "         -19.1341, -17.1933, -10.9029, -25.8700, -16.8629, -14.8478, -13.0844,\n",
       "         -18.7050, -12.6407, -16.2856, -13.8479, -16.7021, -22.5023, -17.0525,\n",
       "         -13.9093, -17.7417, -27.2551, -27.1624, -12.1998, -18.2231, -15.7142,\n",
       "         -19.5300, -11.4803, -16.1769, -14.8128, -22.7181, -23.9491, -14.1029,\n",
       "         -15.0320, -13.3144, -15.0658, -14.3549,  -8.6601, -24.9784, -12.7911,\n",
       "         -17.2927, -23.4602, -16.0806, -19.2460, -21.8168, -18.4788, -23.3423,\n",
       "          -9.3935, -16.7232, -16.0190, -24.6118, -13.7578, -22.2054, -22.5835,\n",
       "         -15.9753, -19.8056, -24.0829, -15.9587, -16.9523, -21.2953, -12.5929,\n",
       "         -19.4705, -18.5707, -15.8618, -21.5629, -19.2696, -18.5080, -13.7233,\n",
       "         -17.3019, -17.1990, -16.7685, -18.7732, -28.9299, -20.6871, -31.9704,\n",
       "         -17.6379, -16.9386, -35.5066, -18.9576, -24.7122, -23.0716, -20.3099,\n",
       "         -16.2932, -24.0186, -19.0690, -21.9035, -21.3719, -30.5782, -20.6703,\n",
       "         -19.5842, -16.6262, -15.8694, -24.6313, -15.9595, -23.9371, -23.0905,\n",
       "         -18.1362, -23.2943, -32.7143, -23.8329, -25.8749, -21.1181, -18.7665,\n",
       "         -21.5089, -18.5923, -27.0737, -30.0264, -29.7861, -26.7743, -22.7755,\n",
       "         -20.1417, -22.7686, -20.7823, -21.5033, -22.9845, -26.7889, -28.7787,\n",
       "         -27.6681, -23.1038, -18.2583, -21.4951, -24.4294, -22.9789, -30.3126,\n",
       "         -23.4502, -14.6518, -20.6279, -31.1364, -19.7544, -18.9433, -26.1301,\n",
       "         -25.4850, -23.7850, -38.7576, -23.8123, -27.0166, -24.9329, -20.9943,\n",
       "         -24.0293, -21.7499, -21.3614, -22.2912, -24.9520, -23.4158, -19.1542,\n",
       "         -24.8924, -26.9676, -28.7132, -30.6930, -22.7458, -23.9620, -20.7802,\n",
       "         -23.1163, -27.2349, -21.2268, -21.9165, -24.4330, -22.9707, -25.9801,\n",
       "         -26.5197, -21.5624, -19.9941, -15.4810, -16.1320, -22.5589, -23.1984,\n",
       "         -24.3739, -20.4529, -30.2082, -27.7092, -27.1996, -24.2140, -29.6681,\n",
       "         -33.2178, -26.0115, -21.8663, -26.4971, -31.9900, -34.2643, -28.7864,\n",
       "         -30.7469, -25.8736],\n",
       "        [ -8.2883, -17.2662, -20.0794,  -8.5302,   9.3649, -15.4345, -11.2105,\n",
       "         -20.0482, -23.4185, -11.0841,  -9.7603, -13.9309, -14.4579,  -9.7989,\n",
       "         -12.3852, -13.4180, -22.8680, -12.4086, -12.8732, -13.3531, -12.1087,\n",
       "         -18.7397, -16.8122, -10.5559, -24.4945, -16.5910, -15.0063, -12.7621,\n",
       "         -18.1280, -12.3315, -15.6476, -13.4221, -16.8808, -21.2180, -17.2491,\n",
       "         -13.2061, -16.8537, -26.3963, -26.0692, -11.9852, -16.9387, -15.2545,\n",
       "         -17.8080, -11.2663, -16.2774, -14.4077, -22.2415, -23.0367, -13.8165,\n",
       "         -14.5858, -12.5525, -14.8424, -13.8644,  -8.8102, -23.6378, -12.9509,\n",
       "         -16.3255, -22.9445, -15.8154, -19.0708, -22.1401, -18.1156, -22.9856,\n",
       "          -9.0743, -16.8383, -16.1455, -24.8390, -13.1934, -22.0868, -23.0229,\n",
       "         -15.3709, -19.8215, -23.5804, -15.3714, -16.2011, -20.4184, -13.0045,\n",
       "         -18.4734, -17.3721, -14.9132, -21.2299, -19.0481, -18.0555, -13.3288,\n",
       "         -15.9634, -16.5370, -17.0308, -18.5900, -27.7168, -20.5987, -31.8266,\n",
       "         -16.9804, -16.8173, -34.8884, -18.1611, -24.4090, -22.2876, -19.5198,\n",
       "         -15.0705, -23.2708, -18.1438, -21.8587, -20.7200, -30.1593, -19.4906,\n",
       "         -18.8322, -16.0286, -15.9321, -25.4511, -15.9215, -23.8767, -22.1932,\n",
       "         -16.6337, -22.6209, -31.6604, -23.8797, -25.9729, -20.7802, -18.1941,\n",
       "         -21.0670, -17.8587, -25.7203, -29.0940, -28.9420, -26.2814, -22.5270,\n",
       "         -19.2869, -22.0784, -20.8830, -20.9705, -22.4144, -26.3314, -28.1810,\n",
       "         -27.0128, -22.4341, -17.5663, -20.7589, -23.3692, -22.1020, -29.4967,\n",
       "         -24.5932, -13.6541, -20.0160, -30.5956, -18.9951, -18.3469, -24.5235,\n",
       "         -24.6881, -22.3560, -38.7245, -22.9930, -26.8226, -23.9978, -21.4505,\n",
       "         -23.8478, -21.8400, -20.5159, -21.8673, -24.2957, -23.1350, -18.1504,\n",
       "         -24.6725, -25.9876, -28.4072, -29.3506, -22.5662, -23.3553, -19.4580,\n",
       "         -22.6868, -26.2436, -19.9709, -21.0735, -24.4872, -22.0703, -25.4941,\n",
       "         -26.0080, -21.4118, -19.4997, -14.6749, -15.0550, -21.5308, -22.9034,\n",
       "         -23.1533, -19.9747, -30.1155, -26.5640, -25.9344, -23.0553, -29.2856,\n",
       "         -32.2328, -25.0054, -20.9831, -25.9177, -31.5594, -33.9792, -28.4718,\n",
       "         -29.0975, -25.5778],\n",
       "        [-10.5116, -17.4548, -19.2321,  -9.2581,   8.6672, -14.6645, -11.0016,\n",
       "         -19.8228, -25.4565, -10.9006,  -8.9981, -14.5440, -15.3777,  -9.7542,\n",
       "         -14.5530, -13.3225, -22.2895, -12.3244, -11.9089, -14.2257, -13.3319,\n",
       "         -17.6122, -18.4874, -10.2980, -24.3853, -15.3731, -16.3238, -12.2150,\n",
       "         -18.5801, -13.6778, -16.1700, -13.4669, -17.3216, -20.4246, -18.4985,\n",
       "         -11.9672, -15.9984, -27.1935, -26.0848, -13.0690, -16.7756, -15.7883,\n",
       "         -17.9147, -10.8551, -17.6482, -14.7995, -23.1509, -22.4024, -13.6600,\n",
       "         -14.8813, -13.3368, -15.3311, -16.0935,  -9.7916, -23.6203, -14.0976,\n",
       "         -15.6374, -23.7277, -16.7418, -19.8921, -23.4507, -19.5426, -23.2841,\n",
       "          -9.2610, -16.8643, -17.9241, -27.0003, -15.8212, -22.3965, -23.4418,\n",
       "         -17.6249, -21.4490, -23.3983, -16.6565, -16.9815, -21.5821, -14.6606,\n",
       "         -19.9934, -16.9478, -15.1023, -22.5769, -19.3757, -17.3202, -13.3751,\n",
       "         -12.8410, -16.7014, -18.2993, -20.4929, -27.5099, -22.7571, -32.8759,\n",
       "         -17.9394, -18.6076, -34.8737, -19.7847, -25.3632, -20.2289, -22.4244,\n",
       "         -15.0980, -24.0775, -17.9257, -21.5074, -22.0109, -31.1817, -21.1619,\n",
       "         -18.6480, -17.3752, -16.5570, -29.0752, -18.1964, -27.0529, -23.5654,\n",
       "         -14.2065, -21.0051, -32.0722, -24.6468, -27.9402, -21.3756, -19.6777,\n",
       "         -21.1887, -19.6381, -25.0311, -31.2876, -29.5473, -27.4369, -24.6029,\n",
       "         -20.4236, -24.5291, -24.4117, -22.5140, -22.3325, -26.9895, -29.2413,\n",
       "         -26.9514, -22.1332, -19.0522, -18.9656, -25.7397, -22.3207, -29.6031,\n",
       "         -25.9636, -14.7604, -21.5311, -31.9462, -18.9668, -17.9947, -23.5134,\n",
       "         -23.2868, -23.6871, -40.5586, -24.5376, -27.7286, -23.2987, -24.1639,\n",
       "         -26.4129, -23.5929, -20.5524, -22.3908, -25.4663, -24.3348, -17.9170,\n",
       "         -24.9148, -26.3692, -28.5175, -28.5878, -22.6191, -25.0362, -20.2329,\n",
       "         -23.6439, -29.5461, -19.8823, -21.3389, -23.8698, -23.2806, -26.6040,\n",
       "         -28.3733, -22.4937, -19.7785, -15.7230, -16.2274, -21.3532, -23.8676,\n",
       "         -23.2865, -21.5704, -30.5340, -27.2875, -26.4981, -23.5051, -30.1992,\n",
       "         -33.2592, -24.4045, -21.4632, -27.6971, -34.0993, -34.9018, -28.6242,\n",
       "         -27.4559, -25.5541]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([121, 198]), torch.Size([121, 198]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states.shape,ground_truth_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([121]), torch.Size([121]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states=torch.cat(predictions_list_states).flatten()\n",
    "ground_truth_list_states=torch.cat(ground_truth_list_states).flatten()\n",
    "predictions_list_states.shape, ground_truth_list_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4,  9,  4,  4,  4, 32, 51, 52,  3,  4,  3,  3,  3,  3,  3,  3, 19, 34,\n",
       "         19,  9, 20, 15,  9,  6,  3, 43,  4, 53,  4, 41,  4,  3,  4, 53,  9,  9,\n",
       "         25, 27, 34, 41,  4,  4,  4, 25,  9, 25, 54,  4, 41, 13, 53, 53, 41, 15,\n",
       "          4,  1, 31,  9,  4, 31,  9,  9, 15, 15, 17,  4,  4,  4,  4, 31, 10, 10,\n",
       "         10, 10, 10, 10, 31, 31,  3,  4,  3, 31,  3,  9, 26, 10,  6, 41, 10, 10,\n",
       "          3, 39, 41,  4,  0,  4, 40, 40, 40,  9,  4, 39, 13, 31,  4, 13,  4, 41,\n",
       "         41, 34,  4, 34, 39,  9, 27,  9, 41, 39, 36, 17,  3]),\n",
       " tensor([ 4,  9,  4,  4,  4, 32, 51, 52,  3,  4,  3,  3,  3,  3,  3,  3, 19, 34,\n",
       "         19,  9, 20, 15,  9,  6,  3, 43,  4, 53,  4, 41,  4,  3,  4, 53,  9,  9,\n",
       "         25, 27, 34, 41,  4,  4,  4, 25,  9, 25, 54,  4, 41, 13, 53, 53, 41, 15,\n",
       "          4,  1, 31,  9,  4, 31,  9,  9, 15, 15, 17,  4,  4,  4,  4, 31, 10, 10,\n",
       "         10, 10, 10, 10, 31, 31,  3,  4,  3, 31,  3,  9, 26, 10,  6, 41, 10, 10,\n",
       "          3, 39, 41,  4,  0,  4, 40, 40, 40,  9,  4, 39, 13, 31,  4, 13,  4, 41,\n",
       "         41, 34,  4, 34, 39,  9, 27,  9, 41, 39, 36, 17,  3]))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200], ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
      "         1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
      "         1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "         1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
      "         1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "         1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
      "         0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
      "         0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "         1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(net_masks_states[..., 0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200]-ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Calculate accuracy USING predicted states and ground truth list states.\n",
    "total_correct = 0\n",
    "total_elements = 0\n",
    "for pred_states, gt_states in zip(predictions_list_states, ground_truth_list_states):\n",
    "    correct = (pred_states == gt_states).float()\n",
    "    total_correct += correct.sum().item()\n",
    "    total_elements += correct.numel()\n",
    "accuracy = total_correct / total_elements if total_elements > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Count  Accuracy Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "4     26     1.0000   1.0000    1.0000 1.0000\n",
      "3     14     1.0000   1.0000    1.0000 1.0000\n",
      "9     13     1.0000   1.0000    1.0000 1.0000\n",
      "10    9      1.0000   1.0000    1.0000 1.0000\n",
      "41    9      1.0000   1.0000    1.0000 1.0000\n",
      "31    7      1.0000   1.0000    1.0000 1.0000\n",
      "15    4      1.0000   1.0000    1.0000 1.0000\n",
      "34    4      1.0000   1.0000    1.0000 1.0000\n",
      "39    4      1.0000   1.0000    1.0000 1.0000\n",
      "53    4      1.0000   1.0000    1.0000 1.0000\n",
      "13    3      1.0000   1.0000    1.0000 1.0000\n",
      "25    3      1.0000   1.0000    1.0000 1.0000\n",
      "40    3      1.0000   1.0000    1.0000 1.0000\n",
      "6     2      1.0000   1.0000    1.0000 1.0000\n",
      "17    2      1.0000   1.0000    1.0000 1.0000\n",
      "19    2      1.0000   1.0000    1.0000 1.0000\n",
      "27    2      1.0000   1.0000    1.0000 1.0000\n",
      "0     1      1.0000   1.0000    1.0000 1.0000\n",
      "1     1      1.0000   1.0000    1.0000 1.0000\n",
      "20    1      1.0000   1.0000    1.0000 1.0000\n",
      "26    1      1.0000   1.0000    1.0000 1.0000\n",
      "32    1      1.0000   1.0000    1.0000 1.0000\n",
      "36    1      1.0000   1.0000    1.0000 1.0000\n",
      "43    1      1.0000   1.0000    1.0000 1.0000\n",
      "51    1      1.0000   1.0000    1.0000 1.0000\n",
      "52    1      1.0000   1.0000    1.0000 1.0000\n",
      "54    1      1.0000   1.0000    1.0000 1.0000\n"
     ]
    }
   ],
   "source": [
    "# filter predictions and ground truth for each unique class\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "filtered_predictions = {}\n",
    "filtered_ground_truth = {}\n",
    "for cls in unique_classes:\n",
    "    mask = (ground_truth_list_states == cls)\n",
    "    filtered_predictions[cls.item()] = predictions_list_states[mask]\n",
    "    filtered_ground_truth[cls.item()] = ground_truth_list_states[mask]\n",
    "\n",
    "# sort classes by frequency\n",
    "class_counts = []\n",
    "for cls in unique_classes:\n",
    "    count = (ground_truth_list_states == cls).sum().item()\n",
    "    class_counts.append((cls.item(), count))\n",
    "\n",
    "# sort by count in descending order\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# compute and print accuracy, precision, recall, and f1 score for each class sorted by frequency\n",
    "print(f\"{'Class':<5} {'Count':<6} {'Accuracy':<8} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    # Get predictions and ground truth for this class\n",
    "    cls_predictions = filtered_predictions[cls]\n",
    "    cls_ground_truth = filtered_ground_truth[cls]\n",
    "    \n",
    "    # Accuracy for this class\n",
    "    accuracy = (cls_predictions == cls_ground_truth).float().mean().item()\n",
    "    \n",
    "    # For precision, recall, F1: need to consider this class vs all others\n",
    "    # True positives: predicted this class and actually this class\n",
    "    tp = ((predictions_list_states == cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # False positives: predicted this class but actually not this class\n",
    "    fp = ((predictions_list_states == cls) & (ground_truth_list_states != cls)).sum().item()\n",
    "    \n",
    "    # False negatives: didn't predict this class but actually this class\n",
    "    fn = ((predictions_list_states != cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {accuracy:<8.4f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Metrics:\n",
      "Overall Accuracy: 1.0000\n",
      "Macro F1 Score: 1.0000\n",
      "Weighted F1 Score: 1.0000\n",
      "Macro Precision: 1.0000\n",
      "Weighted Precision: 1.0000\n",
      "Macro Recall: 1.0000\n",
      "Weighted Recall: 1.0000\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00        14\n",
      "           4       1.00      1.00      1.00        26\n",
      "           6       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      1.00      1.00         9\n",
      "          13       1.00      1.00      1.00         3\n",
      "          15       1.00      1.00      1.00         4\n",
      "          17       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         1\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         7\n",
      "          32       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         4\n",
      "          36       1.00      1.00      1.00         1\n",
      "          39       1.00      1.00      1.00         4\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         9\n",
      "          43       1.00      1.00      1.00         1\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       1.00      1.00      1.00         1\n",
      "          53       1.00      1.00      1.00         4\n",
      "          54       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00       121\n",
      "   macro avg       1.00      1.00      1.00       121\n",
      "weighted avg       1.00      1.00      1.00       121\n",
      "\n",
      "\n",
      "Class Count  Freq%  Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "4     26     21.5   1.0000    1.0000 1.0000\n",
      "3     14     11.6   1.0000    1.0000 1.0000\n",
      "9     13     10.7   1.0000    1.0000 1.0000\n",
      "10    9      7.4    1.0000    1.0000 1.0000\n",
      "41    9      7.4    1.0000    1.0000 1.0000\n",
      "31    7      5.8    1.0000    1.0000 1.0000\n",
      "15    4      3.3    1.0000    1.0000 1.0000\n",
      "34    4      3.3    1.0000    1.0000 1.0000\n",
      "39    4      3.3    1.0000    1.0000 1.0000\n",
      "53    4      3.3    1.0000    1.0000 1.0000\n",
      "13    3      2.5    1.0000    1.0000 1.0000\n",
      "25    3      2.5    1.0000    1.0000 1.0000\n",
      "40    3      2.5    1.0000    1.0000 1.0000\n",
      "6     2      1.7    1.0000    1.0000 1.0000\n",
      "17    2      1.7    1.0000    1.0000 1.0000\n",
      "19    2      1.7    1.0000    1.0000 1.0000\n",
      "27    2      1.7    1.0000    1.0000 1.0000\n",
      "0     1      0.8    1.0000    1.0000 1.0000\n",
      "1     1      0.8    1.0000    1.0000 1.0000\n",
      "20    1      0.8    1.0000    1.0000 1.0000\n",
      "26    1      0.8    1.0000    1.0000 1.0000\n",
      "32    1      0.8    1.0000    1.0000 1.0000\n",
      "36    1      0.8    1.0000    1.0000 1.0000\n",
      "43    1      0.8    1.0000    1.0000 1.0000\n",
      "51    1      0.8    1.0000    1.0000 1.0000\n",
      "52    1      0.8    1.0000    1.0000 1.0000\n",
      "54    1      0.8    1.0000    1.0000 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Convert to numpy for sklearn compatibility\n",
    "gt_numpy = ground_truth_list_states.cpu().numpy()\n",
    "pred_numpy = predictions_list_states.cpu().numpy()\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(gt_numpy, pred_numpy)\n",
    "macro_f1 = f1_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_f1 = f1_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_precision = precision_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_precision = precision_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_recall = recall_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_recall = recall_score(gt_numpy, pred_numpy, average='weighted')\n",
    "\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(gt_numpy, pred_numpy))\n",
    "\n",
    "# Class-wise metrics accounting for imbalance\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "class_counts = [(cls.item(), (ground_truth_list_states == cls).sum().item()) for cls in unique_classes]\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\n{'Class':<5} {'Count':<6} {'Freq%':<6} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    freq_pct = (count / len(ground_truth_list_states)) * 100\n",
    "    \n",
    "    # Calculate metrics for this specific class\n",
    "    cls_mask_gt = (gt_numpy == cls)\n",
    "    cls_mask_pred = (pred_numpy == cls)\n",
    "    \n",
    "    tp = ((pred_numpy == cls) & (gt_numpy == cls)).sum()\n",
    "    fp = ((pred_numpy == cls) & (gt_numpy != cls)).sum()\n",
    "    fn = ((pred_numpy != cls) & (gt_numpy == cls)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {freq_pct:<6.1f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions in tensor([4]) ground truth: 26\n",
      "Accuracy of correct predictions in tensor([4]) ground truth: 1.0\n",
      "Number of correct predictions in tensor([ 4,  3,  9, 10]) ground truth: 62\n",
      "Accuracy of correct predictions in tensor([ 4,  3,  9, 10]) ground truth: 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the number of correct predictions for classes in top_10_ground_truth\n",
    "#top_k=[top_1_ground_truth, top_5_ground_truth, top_10_ground_truth, top_20_ground_truth]\n",
    "top_k=[top_1_ground_truth, top_4_ground_truth]\n",
    "for i in range(len(top_k)):\n",
    "    filtered_gt = ground_truth_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "    filtered_pred = predictions_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "\n",
    "    # get the number of correct predictions and accuracy\n",
    "    correct_predictions = (filtered_pred == filtered_gt).sum()\n",
    "    accuracy = correct_predictions / filtered_gt.numel()\n",
    "    print(f\"Number of correct predictions in {top_k[i]} ground truth: {correct_predictions.item()}\")\n",
    "    print(f\"Accuracy of correct predictions in {top_k[i]} ground truth: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that model is working properly below.\n",
    "\n",
    "-0.0207 is the index for mask value to be filled in. Corresponding mask is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) x_sample[0,:,0]\n",
    "# tensor([-0.9309, -2.4709, -0.9647, -2.5226, -0.9906, -2.6224, -1.0323, -2.6396,\n",
    "#         -1.0287, -2.5965, -0.0207, -0.0207, -1.0252, -2.4983, -1.0098, -0.0207,\n",
    "#         -1.0417, -2.3514, -0.0207, -0.0207, -0.0207, -2.3262, -0.9608, -2.4531,\n",
    "#         -0.9609, -2.5430, -0.0207, -2.4288, -0.0207, -1.5484, -0.9251, -2.4177,\n",
    "#         -0.0207, -0.0207, -0.8637, -2.3879, -0.8872, -0.0207, -0.9029, -2.3117,\n",
    "#         -0.9281, -2.3534, -1.0126, -2.4598, -0.9165, -0.0207, -0.8610, -2.4906,\n",
    "#         -0.0207, -2.5534, -1.0234, -0.8551, -2.4868, -0.8567, -2.4971, -0.9002,\n",
    "#         -2.4162, -0.0207, -0.0207, -0.9232, -0.0207, -0.9814, -0.0207, -0.0207,\n",
    "#         -2.3403, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) masks['states']\n",
    "# tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
    "#         0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "#         0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
