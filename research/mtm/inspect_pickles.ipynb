{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/data/home/umang/Trajectory_project/GPS-MTM/outputs/test_geolife/2025-08-29_11-10-58/test_outputs/random_masking_0.15_testing/ID\"\n",
    "pred_pickle_path=\"{}/predictions_batch_2.pkl\".format(folder)\n",
    "batch_pickle_path = \"{}/ground_truth_batch_2.pkl\".format(folder)\n",
    "attention_pickle_path = \"{}/attention_masks_batch_2.pkl\".format(folder)\n",
    "masks_pickle_path = \"{}/masks_batch_2.pkl\".format(folder)\n",
    "with open(pred_pickle_path, 'rb') as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "with open(batch_pickle_path, 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "with open(attention_pickle_path, 'rb') as f:\n",
    "    attention_masks = pickle.load(f)\n",
    "\n",
    "with open(masks_pickle_path, 'rb') as f:\n",
    "    masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2549])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks['states'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2549, 198])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"states\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2549, 11])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"actions\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most frequently top-5 most repeated in ground_truth_list_States\n",
    "# #don't use torch top-k..\n",
    "ground_truth_list_states = []\n",
    "for i in range(len(attention_masks)):\n",
    "     # first zero mask is first time when attention_masks[i] becomes zero\n",
    "    zero_indices = (attention_masks[i].flatten() == 0).nonzero(as_tuple=True)[0]\n",
    "    first_zero_mask = zero_indices[0].item() if len(zero_indices) > 0 else attention_masks[i].numel()\n",
    "    \n",
    "    ground_truth_states= batch[\"states\"][i, :first_zero_mask, :]\n",
    "    ground_truth_states = torch.argmax(ground_truth_states, dim=-1)\n",
    "    ground_truth_list_states.append(ground_truth_states)\n",
    "\n",
    "k=4\n",
    "ground_truth_list_states = torch.cat(ground_truth_list_states).flatten()\n",
    "unique, counts = torch.unique(ground_truth_list_states, return_counts=True)\n",
    "top_k_ground_truth = unique[torch.topk(counts, k=k).indices]\n",
    "top_k_ground_truth\n",
    "\n",
    "top_1_ground_truth = unique[torch.topk(counts, k=1).indices]\n",
    "top_4_ground_truth = unique[torch.topk(counts, k=4).indices]    \n",
    "# top_5_ground_truth = unique[torch.topk(counts, k=5).indices]\n",
    "# top_10_ground_truth = unique[torch.topk(counts, k=10).indices]\n",
    "# top_20_ground_truth = unique[torch.topk(counts, k=20).indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[68.0000,  0.0000,  6.0000,  ...,  0.2329,  0.1602, -0.1035],\n",
       "        [68.0000,  1.0000,  0.0000,  ...,  0.2304,  0.1599, -0.1035],\n",
       "        [68.0000,  1.0000,  0.0000,  ...,  0.2328,  0.1602, -0.1035],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['actions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'states': tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64),\n",
       " 'actions': tensor([1., 1., 1.,  ..., 0., 0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "predictions_list_states=[]\n",
    "predictions_list_actions=[]\n",
    "ground_truth_list_states=[]\n",
    "ground_truth_list_actions=[]\n",
    "correct_list=[]\n",
    "\n",
    "\n",
    "# Get mask for this sequence\n",
    "mask_states = masks[\"states\"] == 1\n",
    "mask_actions = masks[\"actions\"] == 1\n",
    "\n",
    "net_masks_states= attention_masks* masks[\"states\"]\n",
    "net_masks_actions= attention_masks* masks[\"actions\"]\n",
    "\n",
    "# Apply masks to get only positions where mask is 1\n",
    "predictions_states = predictions[\"states\"][net_masks_states.bool(), :]\n",
    "predictions_actions = predictions[\"actions\"][net_masks_actions.bool(), :]\n",
    "ground_truth_states = batch[\"states\"][net_masks_states.bool(), :]\n",
    "ground_truth_actions = batch[\"actions\"][net_masks_actions.bool(), :]\n",
    "\n",
    "# take argmax of predictions states on last dimension\n",
    "\n",
    "predictions_list_states.append(torch.argmax(predictions_states, dim=-1))\n",
    "predictions_list_actions.append(torch.argmax(predictions_actions, dim=-1))\n",
    "ground_truth_list_states.append(torch.argmax(ground_truth_states, dim=-1))\n",
    "ground_truth_list_actions.append(torch.argmax(ground_truth_actions, dim=-1))\n",
    "\n",
    "print(ground_truth_states)\n",
    "correct = (predictions_states == ground_truth_states).float()\n",
    "correct_list.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_masks_states[..., 0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.6315,  -2.2407,  -5.0313,  -6.2656,  -0.9350, -12.1295,  -5.5427,\n",
       "           1.0801,  -6.7113,   8.5423,   5.2822,  -3.7694,  -3.2153,  -4.2131,\n",
       "          -8.9773,   4.0336,  -9.8856,  -0.0458,  -4.3188,  -1.4296,   3.4820,\n",
       "         -11.8377,  -9.4281,  -6.3491, -14.4032,  -9.1631,  -0.9988,  -5.5367,\n",
       "           2.3195,  -1.5518,  -5.3880,  -8.8343,  -6.1586,  -8.7184,   1.7342,\n",
       "          -6.4831,  -3.6416,  -4.3685,  -9.1126,  -7.8347, -11.8326,  -8.1309,\n",
       "          -7.4324,  -4.4095,  -3.2334,  -5.2041,  -6.3862, -11.2189, -17.1146,\n",
       "          -6.8851, -13.3963, -15.6818,  -7.6069,  -8.9787, -21.1135,  -8.8142,\n",
       "          -4.2848, -10.4388,  -3.5807,  -7.8143,  -0.1464,  -9.4697,  -8.5382,\n",
       "           0.9771,  -5.2748, -12.3274, -11.6152, -10.8967,  -8.8121,  -5.7624,\n",
       "         -15.4035,  -4.2832,  -8.8877,  -1.5747, -12.2615, -16.0500, -13.2349,\n",
       "          -9.2596,  -7.1876, -14.7222,  -0.4266, -12.3616,  -5.0494,  -8.6724,\n",
       "          -9.5940,  -4.8098, -10.4608,  -3.8335, -24.9483, -11.7699, -15.4776,\n",
       "         -13.3370,  -4.0763, -10.2368, -13.8514,  -6.9283,  -4.6844, -14.2247,\n",
       "          -8.3742, -13.8354, -19.3982,  -9.5048, -10.6188,  -4.5292, -18.4096,\n",
       "          -6.8793,  -9.1880,  -4.9382, -12.0997, -15.1409, -14.9136, -15.5920,\n",
       "          -4.7366,  -7.4632, -11.3763, -12.9354,  -7.6730,  -7.4456,  -5.8790,\n",
       "          -6.7484, -12.2626, -11.8038, -18.1685, -18.1148, -12.0418, -11.7955,\n",
       "         -12.7092, -16.8262, -10.7107,  -8.5451,  -2.1358, -10.3504, -14.8076,\n",
       "         -18.5958, -13.2982, -10.1273, -17.1024, -13.9498, -13.7539, -16.9709,\n",
       "          -3.2063,  -5.0718, -10.9807, -11.3116,  -8.8994, -14.5860, -15.0494,\n",
       "         -15.1298, -14.2981, -18.4994, -11.5757, -25.9866, -24.1036, -12.1988,\n",
       "         -25.4196, -18.0418, -22.9630, -12.1873, -22.8435,  -9.7875, -20.6491,\n",
       "         -20.7777, -17.8437, -21.1736, -14.4134, -18.0839, -20.1684, -20.2840,\n",
       "         -22.3182, -21.0638, -19.3787, -21.1833, -17.4363, -13.4649, -11.1821,\n",
       "         -23.2736, -23.0143, -18.3686,  -9.5273, -26.0892, -11.4268, -20.4405,\n",
       "         -22.2401, -21.1255, -17.8438, -15.7465, -14.5792, -17.3666, -12.4415,\n",
       "         -21.7221, -15.1478, -16.9801, -13.5426, -17.4355, -17.9895, -25.8136,\n",
       "         -22.8358, -19.2127],\n",
       "        [ -8.0880,  -0.4840,  -6.2646,  -1.1489,   4.8870, -17.6964,  -6.4073,\n",
       "          -0.5346,   3.1761,   2.3568,   6.3670,  -4.4098,  -0.6989,  -3.6058,\n",
       "          -9.0219,   4.6051, -17.6842,  -3.6175,  -3.8124,  -5.3063,   0.7131,\n",
       "         -12.6755,  -5.1450,  -7.9855, -16.9260, -10.7556,  -1.2120,  -7.2296,\n",
       "          -2.1515,  -4.6957,  -0.6599, -14.6471,  -9.8282,  -4.2918,   1.5095,\n",
       "          -9.2026,  -6.3879,  -9.8698, -12.7667,  -6.2438, -12.1913, -12.5755,\n",
       "          -7.0313,  -7.3628,   0.3233,  -3.1913,  -8.5622, -14.8025,  -9.4170,\n",
       "          -7.3676, -12.1735, -16.6625,  -6.5150,  -4.8956, -21.5481,  -1.9026,\n",
       "          -4.2532,  -6.4628,  -1.1135,  -8.6503,  -0.1775, -11.8787,  -8.7177,\n",
       "           1.9360,  -7.9028, -14.3425, -14.5690,  -6.7486,  -9.5599,  -9.2569,\n",
       "         -12.1167,  -3.8576, -16.5379,  -2.6568, -10.5015, -14.5846, -10.1628,\n",
       "          -7.2189,  -6.6227, -17.9485,  -4.7590, -11.3975,  -7.8626,  -5.9154,\n",
       "         -17.2934,  -9.4353,  -7.6166,  -7.9753, -26.6060,  -7.4908, -12.7540,\n",
       "         -14.2498,  -3.4361, -14.1529, -12.6206,  -9.0879, -17.6800, -14.0966,\n",
       "         -11.7112, -15.1037, -17.6551, -16.1366, -11.7963,  -3.5066, -18.7681,\n",
       "          -7.4625,  -8.3620,  -7.9063, -13.7242, -15.6910, -12.3081, -13.0898,\n",
       "          -8.0387,  -8.5379,  -7.5937, -12.5260, -12.0084,  -6.3071,  -8.6086,\n",
       "          -7.3429, -14.5489,  -2.9941,  -8.2731, -12.2368, -11.0609, -12.3616,\n",
       "         -11.7941, -11.9580, -10.3551,  -8.6305,  -8.5222, -12.1718, -15.9383,\n",
       "         -19.2207,  -9.5605, -10.1481, -13.8732, -18.7847, -12.8112, -18.8700,\n",
       "          -7.6799,  -9.8356,  -6.2609, -12.5201, -15.1485, -14.0073, -14.4384,\n",
       "         -18.2038, -14.2452, -22.4319, -10.3814, -27.1278, -26.8780, -11.7977,\n",
       "         -27.3174, -16.0954, -17.5930, -12.3705, -19.0458,  -8.9110, -22.6816,\n",
       "         -23.5769, -19.8952, -28.3221, -16.2371, -20.8935, -16.6259, -20.4958,\n",
       "         -18.9679, -18.6345, -20.0115, -17.3603, -15.9414, -11.6316, -13.4225,\n",
       "         -21.7776, -24.5874, -14.7156, -11.9108, -22.2818, -14.0265, -22.3218,\n",
       "         -25.9355, -19.6595, -18.2841, -19.3598, -11.4776, -14.9943, -21.3006,\n",
       "         -25.0767, -20.9057, -20.0485, -21.2470, -18.3416, -17.7885, -23.2407,\n",
       "         -25.3801, -19.9007],\n",
       "        [ -5.1510,  -2.3080, -13.1625,   0.0779,   5.2165,  -8.7015,  -4.2789,\n",
       "          -0.3618,   2.0169,   4.4611,  -0.0679,  -4.6892,  -5.3650,   2.9671,\n",
       "          -1.9202,   1.8222, -13.5640,  -1.3558,  -9.8881,  -6.2440,  -2.2891,\n",
       "          -1.2468,  -9.4600, -11.5429, -15.5057,  -3.3992,  -6.7612,  -6.7159,\n",
       "          -9.4654,   1.8616,   3.5629,  -2.4833,  -6.6278,  -4.2274,   0.3570,\n",
       "          -7.9508,  -7.5327, -11.9731, -11.8206,  -3.8777, -11.5235, -11.8374,\n",
       "         -13.0792,  -6.5938,   4.8826,  -3.2758,  -7.5404, -15.6230,   2.9076,\n",
       "          -7.1055,  -6.7295, -11.5494,  -8.3848,   2.2094, -11.9666,  -0.0789,\n",
       "         -15.2658,  -3.9613,   0.4161, -14.8634,  -7.8379, -14.2325, -12.3720,\n",
       "          -4.5133,  -6.3025,  -1.7759, -15.0015,  -3.7309,  -2.8789, -11.6645,\n",
       "          -5.1753,  -5.8973, -20.6469,  -3.1854,  -3.0262, -11.4640,  -6.3534,\n",
       "          -5.9255, -12.8827,  -6.6407,  -6.8566, -14.1261,  -5.7945,  -4.9764,\n",
       "         -11.5268,  -0.6995,  -4.9979,  -8.0882, -23.7610,  -7.0609,  -9.7446,\n",
       "          -9.6657,  -8.2403,  -5.7088,  -1.2680, -13.5001, -17.7299, -15.6898,\n",
       "         -16.6730, -17.1318,  -8.5860, -12.2239, -19.7575,  -6.0225, -11.2467,\n",
       "          -7.1718,  -7.4018,  -5.1287,  -6.6365,  -8.8330,  -9.0441,  -8.2735,\n",
       "         -10.9778,  -7.2003,  -7.2856, -15.8824, -17.3692,  -8.0255,  -5.8664,\n",
       "          -6.6971,  -7.2301,  -6.0991,  -0.4706, -16.0868,  -7.1346,  -8.9444,\n",
       "         -11.5005, -12.6256,  -1.5114,  -9.0536, -11.8360,  -4.2965, -16.3472,\n",
       "         -11.0350, -11.1904, -14.4052,  -6.6135, -15.7986,  -9.6149,  -4.7218,\n",
       "          -4.8278, -12.9309,  -5.9547, -16.4392, -12.1279,  -8.9652, -15.7623,\n",
       "         -15.3719, -12.3306, -17.4596, -12.6295, -23.1186, -23.3080,  -1.1439,\n",
       "         -22.9338, -19.0390, -10.7455,  -6.7308, -10.7897, -14.9501, -20.0496,\n",
       "         -15.4564, -14.7911, -12.5146, -12.2297, -17.3685, -12.9073, -17.9248,\n",
       "         -12.3818, -21.3823, -17.3277, -15.4960, -16.6389, -18.1706, -12.7211,\n",
       "         -10.3714, -15.7658, -16.2282, -12.8856, -18.2930, -16.7827, -10.3198,\n",
       "         -15.2914, -12.1644,  -8.5316, -13.8817, -14.6282, -12.5542, -21.5679,\n",
       "         -12.2805, -17.2064, -17.7876, -18.7280, -12.6493, -10.8494, -15.9369,\n",
       "         -15.8473, -20.7718],\n",
       "        [ -7.2361,  -3.8934, -14.8445,  -0.5880,   1.9175, -10.2350,  -8.8544,\n",
       "          -2.6059,  -1.3721,   1.5706,   0.1247,  -1.8098,  -7.5433,   4.1302,\n",
       "          -5.1642,   3.8855, -14.2267,  -2.6002, -11.8524,  -5.8471,  -0.6658,\n",
       "          -3.8529,  -8.9906, -14.4233, -16.5080,  -0.3995,  -6.2020,  -6.0830,\n",
       "         -13.7512,   1.4629,  -3.3367,  -4.8792,  -5.3359,  -7.8007,  -1.8269,\n",
       "          -5.8184,  -7.6527, -13.8004, -15.2705,  -0.8358,  -9.4038,  -9.7068,\n",
       "         -17.2201,  -8.7257,   2.4767,  -5.5962,  -9.3480, -14.7225,   7.2430,\n",
       "          -9.4817,  -7.6806, -10.7993, -11.1964,   2.1796,  -8.2881,  -0.3605,\n",
       "         -17.2224,  -5.2656,   0.6244, -14.9780, -10.2586, -14.7611, -11.8764,\n",
       "          -8.2429,  -7.3347,  -1.7716, -16.8989,  -3.2081,  -4.6629, -13.5321,\n",
       "          -6.2307,  -7.5293, -19.7040,  -2.5886,  -4.3817, -10.9225,  -8.2251,\n",
       "         -10.2293, -16.2931,  -6.1087,  -4.2677, -13.3995,  -7.5034,  -7.4833,\n",
       "         -10.3750,  -6.1315,  -6.1760, -11.9474, -23.7641, -10.2409,  -8.6207,\n",
       "          -8.8439,  -9.0964,  -3.9710,  -1.2695, -13.2995, -22.9421, -16.6269,\n",
       "         -14.9187, -16.0534,  -3.7141, -12.8685, -20.3671,  -7.9212, -10.9329,\n",
       "          -8.8796,  -5.3963,  -6.7705,  -4.9679,  -5.7604,  -8.7280,  -3.8900,\n",
       "         -10.7943,  -9.0431,  -9.2112, -13.0159, -16.8413,  -8.9961,  -4.7682,\n",
       "         -10.4588,  -6.5542,  -8.6680,  -2.8886, -17.3776,  -8.5251, -10.0702,\n",
       "         -10.1433, -13.2763,  -1.5137, -10.7488, -11.6408,  -2.4242, -18.9671,\n",
       "         -13.5568, -11.8667, -18.0332,  -9.4312, -18.8509,  -8.6010,  -4.6576,\n",
       "         -10.0033, -12.4290,  -9.0528, -18.1481, -15.6336,  -9.2106, -15.6474,\n",
       "         -15.4120, -11.3712, -17.5340, -14.7291, -24.1899, -24.1523,  -1.7417,\n",
       "         -23.4423, -20.1495, -10.3032,  -5.2038, -11.1140, -16.2246, -18.8252,\n",
       "         -13.8922, -14.2260, -10.8434, -11.9805, -15.5911,  -9.1748, -19.5895,\n",
       "         -10.9515, -20.4155, -20.0202, -12.9812, -20.7257, -14.5147, -11.5007,\n",
       "         -12.3037, -15.5297, -17.1710, -13.6559, -16.8477, -19.1160, -13.1850,\n",
       "         -16.5558, -11.1591, -10.2685, -16.0538, -15.4826, -12.2505, -22.5714,\n",
       "         -15.4081, -19.2168, -19.6449, -21.0746, -16.2015,  -9.4542, -16.3119,\n",
       "         -15.4162, -20.2975],\n",
       "        [ -6.5380,   2.8335, -10.4064,   0.7198,   2.9815,  -9.0053, -11.7869,\n",
       "          -6.2259,  -0.9710,   6.9440,  -3.9203,   0.9904,  -2.6619,   5.2687,\n",
       "          -7.2264,   3.6003,  -8.3667,  -2.1060,  -8.7471,  -2.4069,   1.3931,\n",
       "          -7.1031,  -8.2166, -10.4928, -14.3845,  -0.6782,  -6.8862,  -3.5535,\n",
       "          -9.8930,  -2.4840,  -4.8534,  -9.9663,  -2.6450,  -6.8158,  -0.8695,\n",
       "          -2.3150,  -0.5716, -10.5945, -13.5405,  -1.0563,  -4.7302,  -3.4096,\n",
       "         -14.1436,  -3.8037,  -7.6816,  -4.6571, -10.1934, -11.9629,   3.7163,\n",
       "          -9.0870, -11.2748,  -9.2589, -13.0584,  -0.1222, -12.2688,   0.6730,\n",
       "         -14.6087,  -7.6312,  -1.1030, -11.3269,  -4.6355, -14.3279, -14.4056,\n",
       "          -7.7224,  -7.3820,  -3.8466, -10.4887,  -3.1223,  -7.0369, -14.7585,\n",
       "          -6.2315,  -8.8375, -14.4013,  -1.3815, -10.2832,  -8.6306,  -5.0198,\n",
       "         -11.5925, -13.6758, -11.5295,  -4.2320, -13.4434, -11.5924, -10.6811,\n",
       "         -11.3354, -12.6700,  -6.0254, -13.4230, -23.2570,  -9.0726,  -8.1706,\n",
       "         -10.3172,  -5.6412,  -5.4026,  -6.5307,  -9.4710, -24.7351, -14.6945,\n",
       "         -16.3467, -14.4358,  -5.6033, -13.7824, -18.2993, -12.0331, -11.7847,\n",
       "         -12.3139,  -5.8099, -15.6845,  -6.3389, -12.0060, -11.4554,  -6.6446,\n",
       "         -10.9349, -15.6562, -14.2667, -10.0274, -11.9493,  -8.0211,  -7.4074,\n",
       "         -13.4718,  -9.3677, -12.1936,  -7.8523, -19.9179,  -8.3562, -10.9623,\n",
       "         -11.3320, -16.4944,  -6.8524, -12.0132, -15.7191,  -4.6127, -17.4377,\n",
       "         -11.7077, -13.9368, -19.6825, -19.0339, -18.8156, -11.8605, -16.9034,\n",
       "         -15.2854,  -7.0434, -14.2337, -19.2652, -19.1407, -12.2795, -16.1741,\n",
       "         -13.7034,  -9.0960, -13.1412, -14.7960, -23.6082, -23.9099,  -9.5718,\n",
       "         -23.1056, -17.7302,  -9.1012,  -5.6476, -13.1472, -16.6141, -20.2007,\n",
       "         -17.2337, -17.9901, -11.4561, -13.9193, -14.0104,  -8.7757, -18.5433,\n",
       "         -10.4660, -19.7114, -21.6399, -11.4017, -19.3912, -14.4779, -16.2623,\n",
       "         -13.4522, -17.7659, -17.2233, -10.1069, -14.8375, -15.0550, -13.5626,\n",
       "         -15.2867,  -9.7128, -12.4287, -10.9885, -17.0362, -14.9872, -19.6313,\n",
       "         -17.9599, -20.0719, -20.8995, -16.0645, -17.6830, -10.2385, -13.4837,\n",
       "         -19.3877, -13.0912]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([509, 198]), torch.Size([509, 198]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states.shape,ground_truth_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([509]), torch.Size([509]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states=torch.cat(predictions_list_states).flatten()\n",
    "ground_truth_list_states=torch.cat(ground_truth_list_states).flatten()\n",
    "predictions_list_states.shape, ground_truth_list_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  9,  10,   4,  48,   9,   9,  17,  17,   4,  17,  17,   9,   9,  34,\n",
       "           4,   4,   4,  45,  45,   9,  60,   8,   9,  32,  59,  34,  34,  34,\n",
       "         120, 120,  13,   9,   9,   4,   9,  15,   3,   3,  60,  13,  63,  15,\n",
       "          15,  34,  13,   4,   9,  29,  59,   9,  25,  15,  15,  43,  43,  17,\n",
       "          20,  26,  20, 106,  73,  13,   9,  10,  26,  17,  17,  17,  17,  15,\n",
       "           3,   3,  20,  31,  55,  15,  82,  63,   9,   9,   4,   4,   4,   4,\n",
       "           4,  73,  73,  15,  15,  25,  19,   4,   4,   4,   3,  15,  19,  29,\n",
       "          20,  10,  25,  17,  17,  10,  25,  25,  19,   9,  12,   4,  39,   4,\n",
       "           9,  39,  15,  15,   5,   4,   4,  18,   9,  15,  15,  15,  73,  44,\n",
       "          39,  17,  17,  15,  15,   9,   9,   4,  26,  26,   9,   9,   6,   9,\n",
       "           9,  13,  13,   9,  20,  15,   6,   3,   3,  17,  17,   9,   4,  13,\n",
       "           1,   4,  15,  15,   4,   6,   6,  15,  78,  78,   4,  11,  15,  82,\n",
       "           9,   4,  15,  55,  34,  82,  32,  86,   4,   4,  29,   4,  15,  29,\n",
       "           4,  27,   9,   9,   6,   4,  29,   9,  34,  10,  55,  10,   4,   4,\n",
       "           4,   4,  29,  20]),\n",
       " tensor([  9,  39,   9,   9,   9,  15,  29,   9,   9,  36,  29,  11,  11,  19,\n",
       "           9,  17,  17,  17,  17,  57,  39,  17,  44,  44,  44,  44,  44,  15,\n",
       "          44, 120,   9,   9,  17,  15,   9,   9,   9,   9,  53,  53,  17,   9,\n",
       "          20,   9,  26,  10,  15,  38,  43,  57,   4,  44,  17,  36,  36,  10,\n",
       "           4,   9,  44,  17,  17,  17,   9,   9,  36,  44,  15,  15,  15,  36,\n",
       "          19,  17,  36,  36,  17,   9,   9,  36,  36,  44,  17,  36,  13,  15,\n",
       "           4,  43,  43,   9,  17,  44,   9,  36,  44,  17,  15,  43,   9,  29,\n",
       "          29,  29,  39,  39,  20,  19,  17,  29,  17,   4,  17,  17,   9,   9,\n",
       "          10,   9,  36,  17,  44,  66,  44,  44,  29,  29,  36,  36,   9,   9,\n",
       "          39,  39,  39,  39,  29,   4,  43,  29,  29,  13,  43,  29,  43,  17,\n",
       "          43,   9,   9,  17,  17,  36,  36,  29,  29,  36,  15,   4,  29,  67,\n",
       "          29,  15,   9,   4,  17,  17,  17,   4,   3,   3,   3,   3,   3,   3,\n",
       "          20,  43,  44,  44,  34,  36,   9,  36,   9,  20,  20,  26,  29,  29,\n",
       "          44,  44,  29,  44,  29,  29,   9,   4,   9,  29,   9,  29,  39,  39,\n",
       "          17,   4,   9,   9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200], ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(net_masks_states[..., 0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, -29,  -5,  39,   0,  -6, -12,   8,  -5, -19, -12,  -2,  -2,  15,\n",
       "         -5, -13, -13,  28,  28, -48,  21,  -9, -35, -12,  15, -10, -10,  19,\n",
       "         76,   0,   4,   0,  -8, -11,   0,   6,  -6,  -6,   7, -40,  46,   6,\n",
       "         -5,  25, -13,  -6,  -6,  -9,  16, -48,  21, -29,  -2,   7,   7,   7,\n",
       "         16,  17, -24,  89,  56,  -4,   0,   1, -10, -27,   2,   2,   2, -21,\n",
       "        -16, -14, -16,  -5,  38,   6,  73,  27, -27, -35, -13, -32,  -9, -11,\n",
       "          0,  30,  30,   6,  -2, -19,  10, -32, -40, -13, -12, -28,  10,   0,\n",
       "         -9, -19, -14, -22,  -3,  -9,   8,  -4,   2,   5,  -5, -13,  30,  -5,\n",
       "         -1,  30, -21,  -2, -39, -62, -40, -26, -20, -14, -21, -21,  64,  35,\n",
       "          0, -22, -22, -24, -14,   5, -34, -25,  -3,  13, -34, -20, -37,  -8,\n",
       "        -34,   4,   4,  -8,   3, -21, -30, -26, -26, -19,   2,   5, -25, -54,\n",
       "        -28, -11,   6,  11, -13, -11, -11,  11,  75,  75,   1,   8,  12,  79,\n",
       "        -11, -39, -29,  11,   0,  46,  23,  50,  -5, -16,   9, -22, -14,   0,\n",
       "        -40, -17, -20, -35, -23, -25,  20,   5,  25, -19,  46, -19, -35, -35,\n",
       "        -13,   0,  20,  11])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200]-ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0589\n"
     ]
    }
   ],
   "source": [
    "## Calculate accuracy USING predicted states and ground truth list states.\n",
    "total_correct = 0\n",
    "total_elements = 0\n",
    "for pred_states, gt_states in zip(predictions_list_states, ground_truth_list_states):\n",
    "    correct = (pred_states == gt_states).float()\n",
    "    total_correct += correct.sum().item()\n",
    "    total_elements += correct.numel()\n",
    "accuracy = total_correct / total_elements if total_elements > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Count  Accuracy Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "9     102    0.1275   0.1566    0.1275 0.1405\n",
      "29    76     0.0263   0.1111    0.0263 0.0426\n",
      "17    61     0.0656   0.1176    0.0656 0.0842\n",
      "44    56     0.0179   0.2000    0.0179 0.0328\n",
      "36    43     0.0000   0.0000    0.0000 0.0000\n",
      "43    34     0.0294   0.2500    0.0294 0.0526\n",
      "15    27     0.0000   0.0000    0.0000 0.0000\n",
      "4     25     0.2400   0.0588    0.2400 0.0945\n",
      "39    13     0.0769   0.1250    0.0769 0.0952\n",
      "13    11     0.0000   0.0000    0.0000 0.0000\n",
      "20    9      0.0000   0.0000    0.0000 0.0000\n",
      "66    9      0.0000   0.0000    0.0000 0.0000\n",
      "3     6      0.0000   0.0000    0.0000 0.0000\n",
      "10    5      0.0000   0.0000    0.0000 0.0000\n",
      "19    5      0.0000   0.0000    0.0000 0.0000\n",
      "32    3      0.0000   0.0000    0.0000 0.0000\n",
      "34    3      0.3333   0.0455    0.3333 0.0800\n",
      "45    3      0.0000   0.0000    0.0000 0.0000\n",
      "7     2      0.0000   0.0000    0.0000 0.0000\n",
      "11    2      0.0000   0.0000    0.0000 0.0000\n",
      "12    2      0.0000   0.0000    0.0000 0.0000\n",
      "26    2      0.0000   0.0000    0.0000 0.0000\n",
      "53    2      0.0000   0.0000    0.0000 0.0000\n",
      "57    2      0.0000   0.0000    0.0000 0.0000\n",
      "21    1      0.0000   0.0000    0.0000 0.0000\n",
      "38    1      0.0000   0.0000    0.0000 0.0000\n",
      "67    1      0.0000   0.0000    0.0000 0.0000\n",
      "105   1      0.0000   0.0000    0.0000 0.0000\n",
      "120   1      1.0000   0.3333    1.0000 0.5000\n",
      "132   1      0.0000   0.0000    0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "# filter predictions and ground truth for each unique class\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "filtered_predictions = {}\n",
    "filtered_ground_truth = {}\n",
    "for cls in unique_classes:\n",
    "    mask = (ground_truth_list_states == cls)\n",
    "    filtered_predictions[cls.item()] = predictions_list_states[mask]\n",
    "    filtered_ground_truth[cls.item()] = ground_truth_list_states[mask]\n",
    "\n",
    "# sort classes by frequency\n",
    "class_counts = []\n",
    "for cls in unique_classes:\n",
    "    count = (ground_truth_list_states == cls).sum().item()\n",
    "    class_counts.append((cls.item(), count))\n",
    "\n",
    "# sort by count in descending order\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# compute and print accuracy, precision, recall, and f1 score for each class sorted by frequency\n",
    "print(f\"{'Class':<5} {'Count':<6} {'Accuracy':<8} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    # Get predictions and ground truth for this class\n",
    "    cls_predictions = filtered_predictions[cls]\n",
    "    cls_ground_truth = filtered_ground_truth[cls]\n",
    "    \n",
    "    # Accuracy for this class\n",
    "    accuracy = (cls_predictions == cls_ground_truth).float().mean().item()\n",
    "    \n",
    "    # For precision, recall, F1: need to consider this class vs all others\n",
    "    # True positives: predicted this class and actually this class\n",
    "    tp = ((predictions_list_states == cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # False positives: predicted this class but actually not this class\n",
    "    fp = ((predictions_list_states == cls) & (ground_truth_list_states != cls)).sum().item()\n",
    "    \n",
    "    # False negatives: didn't predict this class but actually this class\n",
    "    fn = ((predictions_list_states != cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {accuracy:<8.4f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Metrics:\n",
      "Overall Accuracy: 0.0589\n",
      "Macro F1 Score: 0.0197\n",
      "Weighted F1 Score: 0.0603\n",
      "Macro Precision: 0.0245\n",
      "Weighted Precision: 0.1078\n",
      "Macro Recall: 0.0336\n",
      "Weighted Recall: 0.0589\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.06      0.24      0.09        25\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.16      0.13      0.14       102\n",
      "          10       0.00      0.00      0.00         5\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00        11\n",
      "          15       0.00      0.00      0.00        27\n",
      "          17       0.12      0.07      0.08        61\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         5\n",
      "          20       0.00      0.00      0.00         9\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         0\n",
      "          29       0.11      0.03      0.04        76\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.00      0.00      0.00         3\n",
      "          34       0.05      0.33      0.08         3\n",
      "          36       0.00      0.00      0.00        43\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.12      0.08      0.10        13\n",
      "          40       0.00      0.00      0.00         0\n",
      "          43       0.25      0.03      0.05        34\n",
      "          44       0.20      0.02      0.03        56\n",
      "          45       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         0\n",
      "          66       0.00      0.00      0.00         9\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         0\n",
      "          70       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          78       0.00      0.00      0.00         0\n",
      "          82       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         0\n",
      "         120       0.33      1.00      0.50         1\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         0\n",
      "         130       0.00      0.00      0.00         0\n",
      "         132       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.06       509\n",
      "   macro avg       0.02      0.03      0.02       509\n",
      "weighted avg       0.11      0.06      0.06       509\n",
      "\n",
      "\n",
      "Class Count  Freq%  Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "9     102    20.0   0.1566    0.1275 0.1405\n",
      "29    76     14.9   0.1111    0.0263 0.0426\n",
      "17    61     12.0   0.1176    0.0656 0.0842\n",
      "44    56     11.0   0.2000    0.0179 0.0328\n",
      "36    43     8.4    0.0000    0.0000 0.0000\n",
      "43    34     6.7    0.2500    0.0294 0.0526\n",
      "15    27     5.3    0.0000    0.0000 0.0000\n",
      "4     25     4.9    0.0588    0.2400 0.0945\n",
      "39    13     2.6    0.1250    0.0769 0.0952\n",
      "13    11     2.2    0.0000    0.0000 0.0000\n",
      "20    9      1.8    0.0000    0.0000 0.0000\n",
      "66    9      1.8    0.0000    0.0000 0.0000\n",
      "3     6      1.2    0.0000    0.0000 0.0000\n",
      "10    5      1.0    0.0000    0.0000 0.0000\n",
      "19    5      1.0    0.0000    0.0000 0.0000\n",
      "32    3      0.6    0.0000    0.0000 0.0000\n",
      "34    3      0.6    0.0455    0.3333 0.0800\n",
      "45    3      0.6    0.0000    0.0000 0.0000\n",
      "7     2      0.4    0.0000    0.0000 0.0000\n",
      "11    2      0.4    0.0000    0.0000 0.0000\n",
      "12    2      0.4    0.0000    0.0000 0.0000\n",
      "26    2      0.4    0.0000    0.0000 0.0000\n",
      "53    2      0.4    0.0000    0.0000 0.0000\n",
      "57    2      0.4    0.0000    0.0000 0.0000\n",
      "21    1      0.2    0.0000    0.0000 0.0000\n",
      "38    1      0.2    0.0000    0.0000 0.0000\n",
      "67    1      0.2    0.0000    0.0000 0.0000\n",
      "105   1      0.2    0.0000    0.0000 0.0000\n",
      "120   1      0.2    0.3333    1.0000 0.5000\n",
      "132   1      0.2    0.0000    0.0000 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Convert to numpy for sklearn compatibility\n",
    "gt_numpy = ground_truth_list_states.cpu().numpy()\n",
    "pred_numpy = predictions_list_states.cpu().numpy()\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(gt_numpy, pred_numpy)\n",
    "macro_f1 = f1_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_f1 = f1_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_precision = precision_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_precision = precision_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_recall = recall_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_recall = recall_score(gt_numpy, pred_numpy, average='weighted')\n",
    "\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(gt_numpy, pred_numpy))\n",
    "\n",
    "# Class-wise metrics accounting for imbalance\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "class_counts = [(cls.item(), (ground_truth_list_states == cls).sum().item()) for cls in unique_classes]\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\n{'Class':<5} {'Count':<6} {'Freq%':<6} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    freq_pct = (count / len(ground_truth_list_states)) * 100\n",
    "    \n",
    "    # Calculate metrics for this specific class\n",
    "    cls_mask_gt = (gt_numpy == cls)\n",
    "    cls_mask_pred = (pred_numpy == cls)\n",
    "    \n",
    "    tp = ((pred_numpy == cls) & (gt_numpy == cls)).sum()\n",
    "    fp = ((pred_numpy == cls) & (gt_numpy != cls)).sum()\n",
    "    fn = ((pred_numpy != cls) & (gt_numpy == cls)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {freq_pct:<6.1f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions in tensor([9]) ground truth: 13\n",
      "Accuracy of correct predictions in tensor([9]) ground truth: 0.12745098769664764\n",
      "Number of correct predictions in tensor([ 9, 29, 17, 44]) ground truth: 20\n",
      "Accuracy of correct predictions in tensor([ 9, 29, 17, 44]) ground truth: 0.06779661029577255\n"
     ]
    }
   ],
   "source": [
    "# get the number of correct predictions for classes in top_10_ground_truth\n",
    "#top_k=[top_1_ground_truth, top_5_ground_truth, top_10_ground_truth, top_20_ground_truth]\n",
    "top_k=[top_1_ground_truth, top_4_ground_truth]\n",
    "for i in range(len(top_k)):\n",
    "    filtered_gt = ground_truth_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "    filtered_pred = predictions_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "\n",
    "    # get the number of correct predictions and accuracy\n",
    "    correct_predictions = (filtered_pred == filtered_gt).sum()\n",
    "    accuracy = correct_predictions / filtered_gt.numel()\n",
    "    print(f\"Number of correct predictions in {top_k[i]} ground truth: {correct_predictions.item()}\")\n",
    "    print(f\"Accuracy of correct predictions in {top_k[i]} ground truth: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that model is working properly below.\n",
    "\n",
    "-0.0207 is the index for mask value to be filled in. Corresponding mask is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) x_sample[0,:,0]\n",
    "# tensor([-0.9309, -2.4709, -0.9647, -2.5226, -0.9906, -2.6224, -1.0323, -2.6396,\n",
    "#         -1.0287, -2.5965, -0.0207, -0.0207, -1.0252, -2.4983, -1.0098, -0.0207,\n",
    "#         -1.0417, -2.3514, -0.0207, -0.0207, -0.0207, -2.3262, -0.9608, -2.4531,\n",
    "#         -0.9609, -2.5430, -0.0207, -2.4288, -0.0207, -1.5484, -0.9251, -2.4177,\n",
    "#         -0.0207, -0.0207, -0.8637, -2.3879, -0.8872, -0.0207, -0.9029, -2.3117,\n",
    "#         -0.9281, -2.3534, -1.0126, -2.4598, -0.9165, -0.0207, -0.8610, -2.4906,\n",
    "#         -0.0207, -2.5534, -1.0234, -0.8551, -2.4868, -0.8567, -2.4971, -0.9002,\n",
    "#         -2.4162, -0.0207, -0.0207, -0.9232, -0.0207, -0.9814, -0.0207, -0.0207,\n",
    "#         -2.3403, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) masks['states']\n",
    "# tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
    "#         0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "#         0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
