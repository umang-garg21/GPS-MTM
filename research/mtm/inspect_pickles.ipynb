{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/data/home/umang/Trajectory_project/GPS-MTM/outputs/test_haystac/2025-08-28_22-02-06/test_outputs/random_masking_0.5_testing/ID\"\n",
    "pred_pickle_path=\"{}/predictions_batch_0.pkl\".format(folder)\n",
    "batch_pickle_path = \"{}/ground_truth_batch_0.pkl\".format(folder)\n",
    "attention_pickle_path = \"{}/attention_masks_batch_0.pkl\".format(folder)\n",
    "masks_pickle_path = \"{}/masks_batch_0.pkl\".format(folder)\n",
    "with open(pred_pickle_path, 'rb') as f:\n",
    "    predictions = pickle.load(f)\n",
    "\n",
    "with open(batch_pickle_path, 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "\n",
    "with open(attention_pickle_path, 'rb') as f:\n",
    "    attention_masks = pickle.load(f)\n",
    "\n",
    "with open(masks_pickle_path, 'rb') as f:\n",
    "    masks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([221])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks['states'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 221, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"states\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 221, 11])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"actions\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most frequently top-5 most repeated in ground_truth_list_States\n",
    "# #don't use torch top-k..\n",
    "ground_truth_list_states = []\n",
    "for i in range(len(attention_masks)):\n",
    "     # first zero mask is first time when attention_masks[i] becomes zero\n",
    "    zero_indices = (attention_masks[i].flatten() == 0).nonzero(as_tuple=True)[0]\n",
    "    first_zero_mask = zero_indices[0].item() if len(zero_indices) > 0 else attention_masks[i].numel()\n",
    "    \n",
    "    ground_truth_states= batch[\"states\"][i, :first_zero_mask, :]\n",
    "    ground_truth_states = torch.argmax(ground_truth_states, dim=-1)\n",
    "    ground_truth_list_states.append(ground_truth_states)\n",
    "\n",
    "k=4\n",
    "ground_truth_list_states = torch.cat(ground_truth_list_states).flatten()\n",
    "unique, counts = torch.unique(ground_truth_list_states, return_counts=True)\n",
    "top_k_ground_truth = unique[torch.topk(counts, k=k).indices]\n",
    "top_k_ground_truth\n",
    "\n",
    "top_1_ground_truth = unique[torch.topk(counts, k=1).indices]\n",
    "top_4_ground_truth = unique[torch.topk(counts, k=4).indices]    \n",
    "# top_5_ground_truth = unique[torch.topk(counts, k=5).indices]\n",
    "# top_10_ground_truth = unique[torch.topk(counts, k=10).indices]\n",
    "# top_20_ground_truth = unique[torch.topk(counts, k=20).indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4000e+03,  1.0000e+00,  0.0000e+00,  ..., -1.3308e+00,\n",
       "          1.6822e+00,  1.2444e-01],\n",
       "        [ 6.4000e+03,  1.0000e+00,  0.0000e+00,  ..., -7.0658e-01,\n",
       "          3.4637e-01, -5.3313e-01],\n",
       "        [ 6.4000e+03,  1.0000e+00,  0.0000e+00,  ..., -9.4772e-01,\n",
       "          1.5863e+00, -9.2767e-01],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['actions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'states': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.], dtype=torch.float64),\n",
       " 'actions': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "predictions_list_states=[]\n",
    "predictions_list_actions=[]\n",
    "ground_truth_list_states=[]\n",
    "ground_truth_list_actions=[]\n",
    "correct_list=[]\n",
    "\n",
    "\n",
    "# Get mask for this sequence\n",
    "mask_states = masks[\"states\"] == 1\n",
    "mask_actions = masks[\"actions\"] == 1\n",
    "\n",
    "net_masks_states= attention_masks* masks[\"states\"]\n",
    "net_masks_actions= attention_masks* masks[\"actions\"]\n",
    "\n",
    "# Apply masks to get only positions where mask is 1\n",
    "predictions_states = predictions[\"states\"][net_masks_states.bool(), :]\n",
    "predictions_actions = predictions[\"actions\"][net_masks_actions.bool(), :]\n",
    "ground_truth_states = batch[\"states\"][net_masks_states.bool(), :]\n",
    "ground_truth_actions = batch[\"actions\"][net_masks_actions.bool(), :]\n",
    "\n",
    "# take argmax of predictions states on last dimension\n",
    "\n",
    "predictions_list_states.append(torch.argmax(predictions_states, dim=-1))\n",
    "predictions_list_actions.append(torch.argmax(predictions_actions, dim=-1))\n",
    "ground_truth_list_states.append(torch.argmax(ground_truth_states, dim=-1))\n",
    "ground_truth_list_actions.append(torch.argmax(ground_truth_actions, dim=-1))\n",
    "\n",
    "print(ground_truth_states)\n",
    "correct = (predictions_states == ground_truth_states).float()\n",
    "correct_list.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_masks_states[..., 0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1782e-01, -6.5436e-01, -1.4165e+00,  1.4867e+00,  4.4587e-01,\n",
       "         -2.4575e+00,  3.9480e-03, -8.2147e-01, -4.2736e-01,  5.6898e-01,\n",
       "         -3.4531e-01, -1.9414e+00, -1.4706e+00,  1.6813e+00, -1.3858e+00,\n",
       "         -1.8213e+00,  4.7368e+00, -2.0860e+00,  5.0565e-01, -1.4970e+00,\n",
       "          3.3623e-01, -1.7075e+00,  5.6587e+00, -9.8836e-01,  6.5560e-01,\n",
       "          6.3920e-01,  5.6433e-03, -8.2847e-01],\n",
       "        [-9.6217e-01, -6.8977e-01, -1.4028e+00,  1.5685e+00,  4.7053e-01,\n",
       "         -2.4907e+00,  6.1584e-02, -8.3536e-01, -5.2259e-01,  7.4119e-01,\n",
       "         -3.1899e-01, -2.0150e+00, -1.3808e+00,  1.7883e+00, -1.3844e+00,\n",
       "         -1.9386e+00,  5.0970e+00, -2.1101e+00,  3.3477e-01, -1.6027e+00,\n",
       "          4.7961e-01, -1.8067e+00,  5.3361e+00, -8.8650e-01,  5.6933e-01,\n",
       "          6.7952e-01, -5.6792e-02, -7.3356e-01],\n",
       "        [-1.1763e+00, -8.0360e-01, -1.4081e+00,  1.5889e+00,  4.7266e-01,\n",
       "         -2.5335e+00,  5.8979e-02, -8.6621e-01, -6.2082e-01,  8.6232e-01,\n",
       "         -3.2535e-01, -2.0543e+00, -1.3155e+00,  1.7502e+00, -1.3051e+00,\n",
       "         -2.0248e+00,  5.3568e+00, -2.1485e+00,  2.8941e-01, -1.6747e+00,\n",
       "          5.9516e-01, -1.9164e+00,  5.1246e+00, -8.2416e-01,  4.8407e-01,\n",
       "          8.6755e-01, -8.9727e-02, -6.4818e-01],\n",
       "        [-1.2836e+00, -9.5432e-01, -1.4373e+00,  1.5986e+00,  4.3385e-01,\n",
       "         -2.6307e+00,  2.3741e-02, -9.0276e-01, -6.7207e-01,  9.0122e-01,\n",
       "         -3.6703e-01, -2.0931e+00, -1.3384e+00,  1.5954e+00, -1.2367e+00,\n",
       "         -2.0882e+00,  5.4757e+00, -2.1883e+00,  3.7281e-01, -1.6977e+00,\n",
       "          6.9131e-01, -2.0070e+00,  5.1644e+00, -8.2760e-01,  4.2383e-01,\n",
       "          1.0595e+00, -7.3213e-02, -5.8045e-01],\n",
       "        [-1.2946e+00, -1.0896e+00, -1.4719e+00,  1.6363e+00,  3.5447e-01,\n",
       "         -2.7423e+00, -1.2732e-02, -9.2657e-01, -6.4730e-01,  8.4520e-01,\n",
       "         -3.9473e-01, -2.1370e+00, -1.3880e+00,  1.4588e+00, -1.2177e+00,\n",
       "         -2.1514e+00,  5.4992e+00, -2.1992e+00,  5.3115e-01, -1.6946e+00,\n",
       "          7.7151e-01, -2.0314e+00,  5.2976e+00, -8.3921e-01,  3.8749e-01,\n",
       "          1.1605e+00, -3.4343e-02, -5.4569e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44, 28]), torch.Size([44, 28]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_states.shape,ground_truth_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44]), torch.Size([44]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states=torch.cat(predictions_list_states).flatten()\n",
    "ground_truth_list_states=torch.cat(ground_truth_list_states).flatten()\n",
    "predictions_list_states.shape, ground_truth_list_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([22, 22, 16, 16, 16, 16, 16, 16, 16, 16, 16, 22, 22, 22, 22, 22, 22, 22,\n",
       "         22, 22, 22, 22, 16, 22, 22, 22, 22, 16, 16, 16, 16, 22, 22, 22, 22, 16,\n",
       "         16, 22, 22, 22, 22, 22, 22, 22]),\n",
       " tensor([22, 16, 16, 16, 22, 16, 22, 16, 22, 16, 22, 22, 16, 22, 16, 22, 16, 22,\n",
       "          3, 22, 22, 22, 16, 22, 16, 22, 16, 22, 16, 22, 16, 22, 16, 22, 16, 22,\n",
       "         16, 22, 16, 22, 22, 22, 16, 22]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200], ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(net_masks_states[..., 0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  6,  0,  0, -6,  0, -6,  0, -6,  0, -6,  0,  6,  0,  6,  0,  6,  0,\n",
       "        19,  0,  0,  0,  0,  0,  6,  0,  6, -6,  0, -6,  0,  0,  6,  0,  6, -6,\n",
       "         0,  0,  6,  0,  0,  0,  6,  0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list_states[0:200]-ground_truth_list_states[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "## Calculate accuracy USING predicted states and ground truth list states.\n",
    "total_correct = 0\n",
    "total_elements = 0\n",
    "for pred_states, gt_states in zip(predictions_list_states, ground_truth_list_states):\n",
    "    correct = (pred_states == gt_states).float()\n",
    "    total_correct += correct.sum().item()\n",
    "    total_elements += correct.numel()\n",
    "accuracy = total_correct / total_elements if total_elements > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Count  Accuracy Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "22    24     0.7083   0.6071    0.7083 0.6538\n",
      "16    19     0.4737   0.5625    0.4737 0.5143\n",
      "3     1      0.0000   0.0000    0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "# filter predictions and ground truth for each unique class\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "filtered_predictions = {}\n",
    "filtered_ground_truth = {}\n",
    "for cls in unique_classes:\n",
    "    mask = (ground_truth_list_states == cls)\n",
    "    filtered_predictions[cls.item()] = predictions_list_states[mask]\n",
    "    filtered_ground_truth[cls.item()] = ground_truth_list_states[mask]\n",
    "\n",
    "# sort classes by frequency\n",
    "class_counts = []\n",
    "for cls in unique_classes:\n",
    "    count = (ground_truth_list_states == cls).sum().item()\n",
    "    class_counts.append((cls.item(), count))\n",
    "\n",
    "# sort by count in descending order\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# compute and print accuracy, precision, recall, and f1 score for each class sorted by frequency\n",
    "print(f\"{'Class':<5} {'Count':<6} {'Accuracy':<8} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    # Get predictions and ground truth for this class\n",
    "    cls_predictions = filtered_predictions[cls]\n",
    "    cls_ground_truth = filtered_ground_truth[cls]\n",
    "    \n",
    "    # Accuracy for this class\n",
    "    accuracy = (cls_predictions == cls_ground_truth).float().mean().item()\n",
    "    \n",
    "    # For precision, recall, F1: need to consider this class vs all others\n",
    "    # True positives: predicted this class and actually this class\n",
    "    tp = ((predictions_list_states == cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # False positives: predicted this class but actually not this class\n",
    "    fp = ((predictions_list_states == cls) & (ground_truth_list_states != cls)).sum().item()\n",
    "    \n",
    "    # False negatives: didn't predict this class but actually this class\n",
    "    fn = ((predictions_list_states != cls) & (ground_truth_list_states == cls)).sum().item()\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {accuracy:<8.4f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Metrics:\n",
      "Overall Accuracy: 0.5909\n",
      "Macro F1 Score: 0.3894\n",
      "Weighted F1 Score: 0.5787\n",
      "Macro Precision: 0.3899\n",
      "Weighted Precision: 0.5741\n",
      "Macro Recall: 0.3940\n",
      "Weighted Recall: 0.5909\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "          16       0.56      0.47      0.51        19\n",
      "          22       0.61      0.71      0.65        24\n",
      "\n",
      "    accuracy                           0.59        44\n",
      "   macro avg       0.39      0.39      0.39        44\n",
      "weighted avg       0.57      0.59      0.58        44\n",
      "\n",
      "\n",
      "Class Count  Freq%  Precision Recall F1    \n",
      "--------------------------------------------------\n",
      "22    24     54.5   0.6071    0.7083 0.6538\n",
      "16    19     43.2   0.5625    0.4737 0.5143\n",
      "3     1      2.3    0.0000    0.0000 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data/home/umang/miniconda3/envs/mtm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Convert to numpy for sklearn compatibility\n",
    "gt_numpy = ground_truth_list_states.cpu().numpy()\n",
    "pred_numpy = predictions_list_states.cpu().numpy()\n",
    "\n",
    "# Overall metrics\n",
    "overall_accuracy = accuracy_score(gt_numpy, pred_numpy)\n",
    "macro_f1 = f1_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_f1 = f1_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_precision = precision_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_precision = precision_score(gt_numpy, pred_numpy, average='weighted')\n",
    "macro_recall = recall_score(gt_numpy, pred_numpy, average='macro')\n",
    "weighted_recall = recall_score(gt_numpy, pred_numpy, average='weighted')\n",
    "\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(gt_numpy, pred_numpy))\n",
    "\n",
    "# Class-wise metrics accounting for imbalance\n",
    "unique_classes = torch.unique(ground_truth_list_states)\n",
    "class_counts = [(cls.item(), (ground_truth_list_states == cls).sum().item()) for cls in unique_classes]\n",
    "class_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\n{'Class':<5} {'Count':<6} {'Freq%':<6} {'Precision':<9} {'Recall':<6} {'F1':<6}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cls, count in class_counts:\n",
    "    freq_pct = (count / len(ground_truth_list_states)) * 100\n",
    "    \n",
    "    # Calculate metrics for this specific class\n",
    "    cls_mask_gt = (gt_numpy == cls)\n",
    "    cls_mask_pred = (pred_numpy == cls)\n",
    "    \n",
    "    tp = ((pred_numpy == cls) & (gt_numpy == cls)).sum()\n",
    "    fp = ((pred_numpy == cls) & (gt_numpy != cls)).sum()\n",
    "    fn = ((pred_numpy != cls) & (gt_numpy == cls)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    print(f\"{cls:<5} {count:<6} {freq_pct:<6.1f} {precision:<9.4f} {recall:<6.4f} {f1:<6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions in tensor([22]) ground truth: 17\n",
      "Accuracy of correct predictions in tensor([22]) ground truth: 0.7083333134651184\n",
      "Number of correct predictions in tensor([22, 16,  3, 13]) ground truth: 26\n",
      "Accuracy of correct predictions in tensor([22, 16,  3, 13]) ground truth: 0.5909090638160706\n"
     ]
    }
   ],
   "source": [
    "# get the number of correct predictions for classes in top_10_ground_truth\n",
    "#top_k=[top_1_ground_truth, top_5_ground_truth, top_10_ground_truth, top_20_ground_truth]\n",
    "top_k=[top_1_ground_truth, top_4_ground_truth]\n",
    "for i in range(len(top_k)):\n",
    "    filtered_gt = ground_truth_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "    filtered_pred = predictions_list_states[(ground_truth_list_states.unsqueeze(-1) == top_k[i]).any(dim=-1)]\n",
    "\n",
    "    # get the number of correct predictions and accuracy\n",
    "    correct_predictions = (filtered_pred == filtered_gt).sum()\n",
    "    accuracy = correct_predictions / filtered_gt.numel()\n",
    "    print(f\"Number of correct predictions in {top_k[i]} ground truth: {correct_predictions.item()}\")\n",
    "    print(f\"Accuracy of correct predictions in {top_k[i]} ground truth: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof that model is working properly below.\n",
    "\n",
    "-0.0207 is the index for mask value to be filled in. Corresponding mask is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) x_sample[0,:,0]\n",
    "# tensor([-0.9309, -2.4709, -0.9647, -2.5226, -0.9906, -2.6224, -1.0323, -2.6396,\n",
    "#         -1.0287, -2.5965, -0.0207, -0.0207, -1.0252, -2.4983, -1.0098, -0.0207,\n",
    "#         -1.0417, -2.3514, -0.0207, -0.0207, -0.0207, -2.3262, -0.9608, -2.4531,\n",
    "#         -0.9609, -2.5430, -0.0207, -2.4288, -0.0207, -1.5484, -0.9251, -2.4177,\n",
    "#         -0.0207, -0.0207, -0.8637, -2.3879, -0.8872, -0.0207, -0.9029, -2.3117,\n",
    "#         -0.9281, -2.3534, -1.0126, -2.4598, -0.9165, -0.0207, -0.8610, -2.4906,\n",
    "#         -0.0207, -2.5534, -1.0234, -0.8551, -2.4868, -0.8567, -2.4971, -0.9002,\n",
    "#         -2.4162, -0.0207, -0.0207, -0.9232, -0.0207, -0.9814, -0.0207, -0.0207,\n",
    "#         -2.3403, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207, -0.0207,\n",
    "#         -0.0207, -0.0207, -0.0207, -0.0207, -0.0207], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Pdb) masks['states']\n",
    "# tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
    "#         0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
    "#         0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
    "#         1, 1, 0, 1, 1], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
