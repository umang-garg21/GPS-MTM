# Test configuration for MTM model evaluation
# Based on the main config.yaml but modified for testing
# Use the 'test_name' field to give custom names to your test runs

defaults:
  - datasets: numosim
  - override hydra/launcher: slurm  
  - override hydra/output: local
  - _self_

model_config:
  _target_: research.mtm.models.mtm_model.MTMConfig
  norm: "none"
  n_embd: 1024
  n_enc_layer: 2
  n_dec_layer: 1
  n_head: 4
  dropout: 0.1
  loss_keys: null
  latent_dim: null

tokenizers:
  states:
    _target_: research.mtm.tokenizers.discrete_identity.DiscreteIdentity.create
    num_classes: 28   # Number of classes for discrete tokenizer
  actions:
    _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create

state_only_dataset: null

# Test-specific arguments
args:
  _target_: research.mtm.test.TestConfig
  seed: 42
  batch_size: 32
  n_workers: 4
  device: cuda
  mask_ratios: [0.8]
  mask_patterns: ["RANDOM", "GOAL", "ID", "FD"]
  traj_length: 221
  mode_order: ["states", "actions"]
  mode_weights: [0.5, 0.5]
  # Path to your trained model checkpoint
  model_path: /data/home/umang/Trajectory_project/GPS-MTM/outputs/mtm_mae/2025-08-16_18-28-54/model_70000.pt
  save_predictions: true
  output_dir: "test_outputs"
  test_name: "default_test"  # Custom name for this test run
  load_test_only: true  # Only load validation data for testing (saves memory and time)

# WandB configuration for test logging
wandb:
  project: "experiments_test"  # Will append "_test" to create separate test project
  entity: ""
  resume: false

job_name: test_job

hydra:
  job:
    name: mtm_test
    chdir: True
